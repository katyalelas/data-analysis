{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'kind': 'pyspark', 'conf': {'spark.master': 'yarn', 'spark.yarn.dist.archives': '/use_case/hhmatching/Library_zip/extra_lib_3.zip#lcm_zip', 'spark.yarn.appMasterEnv.PYSPARK_PYTHON': './lcm_zip/bin/python', 'spark.driver.cores': '2', 'spark.driver.memory': '6000m', 'spark.executor.memory': '6000m', 'spark.executor.cores': '2', 'spark.dynamicAllocation.enabled': 'true', 'spark.dynamicAllocation.minExecutors': '2'}}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>1160</td><td>application_1620749185953_126168</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://lxcdhmasterv1d.dc.ht.hr:8088/proxy/application_1620749185953_126168/\">Link</a></td><td><a target=\"_blank\" href=\"http://lxcdhworkerph4d.dc.ht.hr:8042/node/containerlogs/container_e60_1620749185953_126168_01_000001/tsystems_ckumar\">Link</a></td><td></td></tr><tr><td>1161</td><td>application_1620749185953_126259</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://lxcdhmasterv1d.dc.ht.hr:8088/proxy/application_1620749185953_126259/\">Link</a></td><td><a target=\"_blank\" href=\"http://lxcdhworkerph1d.dc.ht.hr:8042/node/containerlogs/container_e60_1620749185953_126259_01_000001/tsystems_vkumar\">Link</a></td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{\n",
    "\"kind\": \"pyspark\",\n",
    "\n",
    "\"conf\": {\n",
    "   \n",
    "    \"spark.master\": \"yarn\",\n",
    "    \"spark.yarn.dist.archives\": \"/use_case/hhmatching/Library_zip/extra_lib_3.zip#lcm_zip\", \n",
    "    \"spark.yarn.appMasterEnv.PYSPARK_PYTHON\": \"./lcm_zip/bin/python\",\n",
    "    \"spark.driver.cores\": \"2\", \n",
    "    \"spark.driver.memory\": \"6000m\",  \n",
    "    \"spark.executor.memory\": \"6000m\",\n",
    "    \"spark.executor.cores\": \"2\", \n",
    "     \"spark.dynamicAllocation.enabled\": \"true\",\n",
    "     \"spark.dynamicAllocation.minExecutors\": \"2\"\n",
    "    \n",
    "      \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>1162</td><td>application_1620749185953_126280</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://lxcdhmasterv1d.dc.ht.hr:8088/proxy/application_1620749185953_126280/\">Link</a></td><td><a target=\"_blank\" href=\"http://lxcdhworkerph1d.dc.ht.hr:8042/node/containerlogs/container_e60_1620749185953_126280_01_000001/bus_klelas\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import QuantileDiscretizer\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import lit,log, when, regexp_replace, col\n",
    "from pyspark.sql.types import DoubleType,IntegerType, StringType, StructField, StructType\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql import dataframe\n",
    "def spark_shape(self):\n",
    "    return (self.count(),len(self.columns))\n",
    "dataframe.DataFrame.shape = spark_shape\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder \n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.feature import PCA\n",
    "from time import time\n",
    "from datetime import timedelta\n",
    "\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"example-spark\")\\\n",
    "    .config(\"spark.sql.crossJoin.enabled\",\"true\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read the csv file, get the shape of the dataset, check data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows = 2540047, number of columns = 50."
     ]
    }
   ],
   "source": [
    "# 1)\n",
    "# read the dataset\n",
    "df=spark.read.csv(\"dataset_test.csv\",header=True, inferSchema=\"true\").withColumn(\"rowId\", F.monotonically_increasing_id())\n",
    "df=df.drop('_c0') \n",
    "# check the shape of the dataset\n",
    "row_num=int(df.count())\n",
    "col_num=len(df.columns)\n",
    "print('number of rows = {}, number of columns = {}.'.format(row_num, col_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical =>  ['srcip', 'sport', 'dstip', 'dsport', 'proto', 'state', 'service', 'is_sm_ips_ports', 'ct_state_ttl', 'is_ftp_login', 'ct_ftp_cmd', 'attack_cat'] len =  12\n",
      "\n",
      "numerical =>  ['dur', 'sbytes', 'dbytes', 'sttl', 'dttl', 'sloss', 'dloss', 'Sload', 'Dload', 'Spkts', 'Dpkts', 'swin', 'dwin', 'stcpb', 'dtcpb', 'smeansz', 'dmeansz', 'trans_depth', 'res_bdy_len', 'Sjit', 'Djit', 'Stime', 'Ltime', 'Sintpkt', 'Dintpkt', 'tcprtt', 'synack', 'ackdat', 'ct_flw_http_mthd', 'ct_srv_src', 'ct_srv_dst', 'ct_dst_ltm', 'ct_src_ ltm', 'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm', 'Label', 'rowId'] len =  38"
     ]
    }
   ],
   "source": [
    "# 2) \n",
    "# check the data types\n",
    "\n",
    "# select columns with distinct values less than 10 and convert them to string:\n",
    "convert_to_cat = list(filter(None, [field if df.groupBy(field ).count().count() < 10 else None for field in df.columns ]))\n",
    "convert_to_cat=['is_sm_ips_ports', 'ct_state_ttl', 'is_ftp_login', 'ct_ftp_cmd']\n",
    "for field in convert_to_cat:\n",
    "    df=df.withColumn(field,F.col(field).cast(StringType()))\n",
    "    \n",
    "## the function dtype(df) returns two lists populated with the column names of continuous (1st list) and categorical (2nd list) columns\n",
    "## the function prints the values in two lists as well as their lenghts\n",
    "## the input of the function is a spark dataframe\n",
    "def dtype(df):\n",
    "    categorical = [field for (field, dataType) in df.dtypes if dataType == 'string']\n",
    "    numerical = [field for (field, dataType) in df.dtypes if dataType == 'double' or dataType == 'int' or dataType == 'bigint' ]\n",
    "    #list of categorical type columns' names\n",
    "    print('categorical => ', categorical, 'len = ', len(categorical))\n",
    "    print()\n",
    "    #list of continuous type columns' names\n",
    "    print('numerical => ', numerical, 'len = ', len(numerical))\n",
    "    return numerical, categorical\n",
    "numerical, categorical = dtype(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            count         mean        stddev  min           max\n",
      "dur     2540047.0         0.66  1.392000e+01  0.0  8.786640e+03\n",
      "sbytes  2540047.0      4339.60  5.640599e+04  0.0  1.435577e+07\n",
      "dbytes  2540047.0     36427.59  1.610960e+05  0.0  1.465753e+07\n",
      "sttl    2540047.0        62.78  7.462000e+01  0.0  2.550000e+02\n",
      "dttl    2540047.0        30.77  4.285000e+01  0.0  2.540000e+02\n",
      "sloss   2540047.0         5.16  2.252000e+01  0.0  5.319000e+03\n",
      "dloss   2540047.0        16.33  5.659000e+01  0.0  5.507000e+03\n",
      "Sload   2540047.0  36956447.51  1.186043e+08  0.0  5.988000e+09\n",
      "Dload   2540047.0   2450861.22  4.224863e+06  0.0  1.287619e+08\n",
      "Spkts   2540047.0        33.29  7.628000e+01  0.0  1.064600e+04"
     ]
    }
   ],
   "source": [
    "# 3)\n",
    "# check descriptive statistics\n",
    "## the function statist\n",
    "def statistics(df):\n",
    "    statistics=df.describe().toPandas().transpose()\n",
    "    statistics.columns=statistics.iloc[0,:].values\n",
    "    statistics=statistics.iloc[1:,:]\n",
    "    return statistics\n",
    "st=statistics(df)\n",
    "# remove string values and convert to integer\n",
    "st_=st[~pd.to_numeric(st['max'], errors='coerce').isnull()]\n",
    "st_=st_[~pd.to_numeric(st_['min'], errors='coerce').isnull()]\n",
    "st_=st_.astype('float')\n",
    "st_=st_.round(decimals=2)\n",
    "st_.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct values in column srcip is 44\n",
      "Number of distinct values in column sport is 64600\n",
      "Number of distinct values in column dstip is 47\n",
      "Number of distinct values in column dsport is 64630\n",
      "Number of distinct values in column proto is 135\n",
      "Number of distinct values in column state is 16\n",
      "Number of distinct values in column service is 13\n",
      "Number of distinct values in column is_sm_ips_ports is 2\n",
      "Number of distinct values in column ct_state_ttl is 7\n",
      "Number of distinct values in column is_ftp_login is 5\n",
      "Number of distinct values in column ct_ftp_cmd is 9\n",
      "Number of distinct values in column attack_cat is 14\n",
      " after optimization:\n",
      "Number of distinct values in column srcip is 19\n",
      "Number of distinct values in column sport is 4\n",
      "Number of distinct values in column dstip is 20\n",
      "Number of distinct values in column dsport is 11\n",
      "Number of distinct values in column proto is 3\n",
      "Number of distinct values in column state is 4"
     ]
    }
   ],
   "source": [
    "# 4) \n",
    "# check disticnt values of categorical columns and optimize categories\n",
    "list_of_columns_to_transform=[]\n",
    "for col in categorical:\n",
    "    d=df.groupBy(col).count().count()\n",
    "    print(\"Number of distinct values in column {} is {}\".format(col,d))\n",
    "    if d > 15: \n",
    "        list_of_columns_to_transform.append(col)\n",
    "        \n",
    "#list_of_columns_to_transform=['srcip', 'dstip', 'dsport', 'sport', 'proto', 'state']\n",
    "print(' after optimization:')\n",
    "for column in list_of_columns_to_transform:\n",
    "    c=df.groupBy(column).count()\n",
    "    c=c.withColumn('ratio', c['count']/df.count()) #calculate a normalized count of unique values\n",
    "    c=c.where(c['ratio']>0.009).select(column).toPandas() # to create a list of values which occur more that 0.01 times \n",
    "    # if a value repeates rarely than in 1% of rows, change this value to a sting \"other\"\n",
    "    df=df.withColumn(column, when(F.col(column).isin([i[0] for i in c.values]), F.col(column)).otherwise('other'))\n",
    "    print(\"Number of distinct values in column {} is {}\".format(column,df.groupBy(column).count().count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+\n",
      "|Label|  count|\n",
      "+-----+-------+\n",
      "|    1| 321283|\n",
      "|    0|2218764|\n",
      "+-----+-------+\n",
      "\n",
      "None\n",
      "+----------------+-------+\n",
      "|      attack_cat|  count|\n",
      "+----------------+-------+\n",
      "|            null|2218764|\n",
      "|         Generic| 215481|\n",
      "|        Exploits|  44525|\n",
      "|        Fuzzers |  19195|\n",
      "|             DoS|  16353|\n",
      "| Reconnaissance |  12228|\n",
      "|         Fuzzers|   5051|\n",
      "|        Analysis|   2677|\n",
      "|        Backdoor|   1795|\n",
      "|  Reconnaissance|   1759|\n",
      "|      Shellcode |   1288|\n",
      "|       Backdoors|    534|\n",
      "|       Shellcode|    223|\n",
      "|           Worms|    174|\n",
      "+----------------+-------+\n",
      "\n",
      "['87.4 %', '8.5 %', '1.8 %', '0.8 %', '0.6 %']"
     ]
    }
   ],
   "source": [
    "# 5.1) \n",
    "#check lable attribute and the distribution of classes\n",
    "\n",
    "# label attribute value counts\n",
    "print(df.groupBy('Label').count().show())\n",
    "\n",
    "#check the ratio of every attack class, select top 5\n",
    "rows=df.count()\n",
    "df.groupBy('attack_cat').count().orderBy('count', ascending=False).show()\n",
    "c=df.groupBy('attack_cat').count().orderBy('count', ascending=False).collect()\n",
    "[str(round(c[i][1]/rows*100, 1))+str(\" %\") for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5.2) \n",
    "#create new target columns \n",
    "df=df.withColumnRenamed('Label', 'target') # 12.6 %\n",
    "df=df.withColumn('target1', when(df['attack_cat']=='Generic', 1).otherwise(0)) # 8.5 %\n",
    "df=df.withColumn('target2', when(df['attack_cat']=='Exploits', 1).otherwise(0)) # 1.8 %\n",
    "df=df.withColumn('target3', when(df['attack_cat']==' Fuzzers ', 1).otherwise(0)) # 0.8 %\n",
    "# drop attack_cat column with types of anomaly, and datetime columns \n",
    "# p.s. datetime columns are useful for feature enginerring and window functions however it is not in the scope of the presented use-case\n",
    "df=df.drop(*['attack_cat','Stime','Ltime']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical =>  ['srcip', 'sport', 'dstip', 'dsport', 'proto', 'state', 'service', 'is_sm_ips_ports', 'ct_state_ttl', 'is_ftp_login', 'ct_ftp_cmd', 'rowId'] len =  12\n",
      "\n",
      "numerical =>  ['dur', 'sbytes', 'dbytes', 'sttl', 'dttl', 'sloss', 'dloss', 'Sload', 'Dload', 'Spkts', 'Dpkts', 'swin', 'dwin', 'stcpb', 'dtcpb', 'smeansz', 'dmeansz', 'trans_depth', 'res_bdy_len', 'Sjit', 'Djit', 'Sintpkt', 'Dintpkt', 'tcprtt', 'synack', 'ackdat', 'ct_flw_http_mthd', 'ct_srv_src', 'ct_srv_dst', 'ct_dst_ltm', 'ct_src_ ltm', 'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm', 'target', 'target1', 'target2', 'target3'] len =  38"
     ]
    }
   ],
   "source": [
    "# cast rowId column to string\n",
    "df = df.withColumn('rowId',df['rowId'].cast(StringType()))\n",
    "# run the function dtype() to get lists of numerical and categorical columns\n",
    "numerical, categorical = dtype(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.08 % of missing values - ct_flw_http_mthd, numerical\n",
      "56.29 % of missing values - is_ftp_login, categorical"
     ]
    }
   ],
   "source": [
    "# 6.1) \n",
    "# proportion of missing values in a column\n",
    "null_fields=[]\n",
    "null_fields_cat=[]\n",
    "for field in df.columns:\n",
    "    if field in categorical:\n",
    "        null_num=int(df.where(F.col(field).isNull()).count())\n",
    "        if null_num>0:\n",
    "            proportion=round(null_num/row_num*100, 2)\n",
    "            null_fields_cat.append(tuple([field, proportion]))\n",
    "            print('{} % of missing values - {}, categorical'.format(proportion, field))\n",
    "    elif field in numerical:\n",
    "        null_num=int(df.where(F.col(field).isNull()).count())\n",
    "        if null_num>0: \n",
    "            proportion=round(null_num/row_num*100, 2)\n",
    "            null_fields.append(tuple([field, proportion]))\n",
    "            print('{} % of missing values - {}, numerical'.format(proportion, field))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nulls are going to be filled in with: -99  \n",
      " \n",
      "Column with null values: ct_flw_http_mthd\n",
      "All clean!"
     ]
    }
   ],
   "source": [
    "# 6.2) \n",
    "#replace missing values with -99\n",
    "\n",
    "#the functin check_nulls(df, value_to_fillin) checks if continuous columns that have null values inlude a value,\n",
    "# which a user wants to replace null values with (value_to_fillin).\n",
    "# the function prints out the result\n",
    "\n",
    "def check_nulls(df, value_to_fillin):\n",
    "    n=int(value_to_fillin)\n",
    "    print(\"Nulls are going to be filled in with: {}  \\n \".format(n))\n",
    "    numerical = [field for (field, dataType) in df.dtypes if dataType == 'double' or dataType == 'int' or dataType == 'bigint' ]\n",
    "    for c in numerical:\n",
    "        if int(df.where(F.col(c).isNull()).count())>0:\n",
    "            print('Column with null values:', c)\n",
    "            n_count=int(df.where(F.col(c)==n).count())\n",
    "            if n_count>0:\n",
    "                print('Oops, the column has {} rows with value'.format(n_count) , n, '. Try another value \\n ')\n",
    "            else: \n",
    "                print(\"All clean!\")\n",
    "\n",
    "check_nulls(df, -99)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#6.3)\n",
    "# make a copy of the dataframe with null values (needed for Weight of Evidence calculation)\n",
    "df_nulls=df\n",
    "# replace null values for numerical columns\n",
    "df=df.fillna(-99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dur rows kept = 2533455 || % of all set = 99.74 || % from what is left 99.74\n",
      "sbytes rows kept = 2532020 || % of all set = 99.68 || % from what is left 99.94\n",
      "dbytes rows kept = 2461920 || % of all set = 96.92 || % from what is left 97.23\n",
      "sttl rows kept = 2132942 || % of all set = 83.97 || % from what is left 86.64\n",
      "dttl rows kept = 2104433 || % of all set = 82.85 || % from what is left 98.66\n",
      "sloss rows kept = 2100179 || % of all set = 82.68 || % from what is left 99.8\n",
      "dloss rows kept = 2100156 || % of all set = 82.68 || % from what is left 100.0\n",
      "Sload rows kept = 2062626 || % of all set = 81.2 || % from what is left 98.21\n",
      "Dload rows kept = 1905712 || % of all set = 75.03 || % from what is left 92.39\n",
      "Spkts rows kept = 1904533 || % of all set = 74.98 || % from what is left 99.94\n",
      "Dpkts rows kept = 1903790 || % of all set = 74.95 || % from what is left 99.96\n",
      "swin rows kept = 1903790 || % of all set = 74.95 || % from what is left 100.0\n",
      "dwin rows kept = 1903790 || % of all set = 74.95 || % from what is left 100.0\n",
      "stcpb rows kept = 1895898 || % of all set = 74.64 || % from what is left 99.59\n",
      "dtcpb rows kept = 1890807 || % of all set = 74.44 || % from what is left 99.73\n",
      "smeansz rows kept = 1763214 || % of all set = 69.42 || % from what is left 93.25\n",
      "dmeansz rows kept = 1752537 || % of all set = 69.0 || % from what is left 99.39\n",
      "trans_depth rows kept = 1747098 || % of all set = 68.78 || % from what is left 99.69\n",
      "res_bdy_len rows kept = 1746854 || % of all set = 68.77 || % from what is left 99.99\n",
      "Sjit rows kept = 1746381 || % of all set = 68.75 || % from what is left 99.97\n",
      "Djit rows kept = 1741997 || % of all set = 68.58 || % from what is left 99.75\n",
      "Sintpkt rows kept = 1733740 || % of all set = 68.26 || % from what is left 99.53\n",
      "Dintpkt rows kept = 1733732 || % of all set = 68.26 || % from what is left 100.0\n",
      "tcprtt rows kept = 1733660 || % of all set = 68.25 || % from what is left 100.0\n",
      "synack rows kept = 1733560 || % of all set = 68.25 || % from what is left 99.99\n",
      "ackdat rows kept = 1733557 || % of all set = 68.25 || % from what is left 100.0\n",
      "ct_flw_http_mthd rows kept = 1733557 || % of all set = 68.25 || % from what is left 100.0\n",
      "ct_srv_src rows kept = 1658223 || % of all set = 65.28 || % from what is left 95.65\n",
      "ct_srv_dst rows kept = 1657989 || % of all set = 65.27 || % from what is left 99.99\n",
      "ct_dst_ltm rows kept = 1645842 || % of all set = 64.8 || % from what is left 99.27\n",
      "ct_src_ ltm rows kept = 1643464 || % of all set = 64.7 || % from what is left 99.86\n",
      "ct_src_dport_ltm rows kept = 1643464 || % of all set = 64.7 || % from what is left 100.0\n",
      "ct_dst_sport_ltm rows kept = 1616015 || % of all set = 63.62 || % from what is left 98.33\n",
      "ct_dst_src_ltm rows kept = 1616015 || % of all set = 63.62 || % from what is left 100.0\n",
      "target rows kept = 1615517 || % of all set = 63.6 || % from what is left 99.97\n",
      "target1 rows kept = 1615517 || % of all set = 63.6 || % from what is left 100.0\n",
      "target2 rows kept = 1615517 || % of all set = 63.6 || % from what is left 100.0\n",
      "target3 rows kept = 1615517 || % of all set = 63.6 || % from what is left 100.0"
     ]
    }
   ],
   "source": [
    "#7)\n",
    "# check outlier and which proportion of data they occupy\n",
    "\n",
    "# create a dataframe with standard deviation values of each column\n",
    "#in order to remove deviated values with more that 3 or 5 std from the mean\n",
    "numerical = [field for (field, dataType) in df.dtypes if dataType == 'double' or dataType == 'int' or dataType == 'bigint']\n",
    "stat=df.select(*numerical).describe()\n",
    "std=stat.where(F.col('summary')=='stddev')\n",
    "std=std.select(*numerical)\n",
    "for i in std.columns:\n",
    "    std = std.withColumn(i,F.col(i).cast(DoubleType()))\n",
    "std=std.toPandas().transpose()\n",
    "std.columns=['std']\n",
    "std['col_name']=std.index.values\n",
    "col_name_list=std.index.values\n",
    "std['3std']=std['std'].apply(lambda x: x*3)\n",
    "std['5std']=std['std'].apply(lambda x: x*5)\n",
    "std=spark.createDataFrame(std)\n",
    "\n",
    "def outliers(df, std, list_of_columns, column_std='3std'):\n",
    "    start=df.count()\n",
    "    for l in list_of_columns:\n",
    "        try:\n",
    "            before=df.count()\n",
    "            scalar_std=std.where(F.col('col_name')==l).select(column_std).collect()[0][0]\n",
    "            df=df.withColumn('{}_{}'.format(column_std, l),F.lit(scalar_std))\n",
    "            b=column_std+'_'+l\n",
    "            df=df.filter(F.abs(F.col(l))<F.col(b))\n",
    "            now=df.count()\n",
    "            print(l, 'rows kept =', now, '|| % of all set =', round(now/start*100, 2), '|| % from what is left' , round(now/before*100, 2) )\n",
    "        except ZeroDivisionError as err:\n",
    "            print(err)\n",
    "outliers (df, std, numerical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight of Evidence and Information Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical =>  ['srcip', 'sport', 'dstip', 'dsport', 'proto', 'state', 'service', 'is_sm_ips_ports', 'ct_state_ttl', 'is_ftp_login', 'ct_ftp_cmd', 'PK_column', 'target'] len =  13\n",
      "\n",
      "numerical =>  ['dur', 'sbytes', 'dbytes', 'sttl', 'dttl', 'sloss', 'dloss', 'Sload', 'Dload', 'Spkts', 'Dpkts', 'swin', 'dwin', 'stcpb', 'dtcpb', 'smeansz', 'dmeansz', 'trans_depth', 'res_bdy_len', 'Sjit', 'Djit', 'Sintpkt', 'Dintpkt', 'tcprtt', 'synack', 'ackdat', 'ct_flw_http_mthd', 'ct_srv_src', 'ct_srv_dst', 'ct_dst_ltm', 'ct_src_ ltm', 'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm'] len =  34"
     ]
    }
   ],
   "source": [
    "# 8)\n",
    "# cast target column to categorical\n",
    "df_nulls = df_nulls.withColumn(\"target3\",  when(df_nulls[\"target3\"] == 1, \"YES\").otherwise(\"NO\"))\n",
    "df_nulls=df_nulls.drop('target', 'target1', 'target2')\n",
    "# change the name of the primary key column to 'PK_column'\n",
    "df_nulls=df_nulls.withColumnRenamed('rowId','PK_column')\n",
    "df_nulls=df_nulls.withColumnRenamed('target3','target')\n",
    "columns_to_remove=set(['Stime', 'Label', 'Ltime', 'dtcpb', 'rowId'])\n",
    "n, c = dtype(df_nulls)\n",
    "list_of_columns=list(set(n)-columns_to_remove)\n",
    "\n",
    "s = StructType([StructField(\"PK_column\", StringType(), True)])\n",
    "d = spark.createDataFrame([], s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ct_dst_sport_ltm', 'dloss', 'Dintpkt', 'Dload', 'Spkts', 'synack', 'ct_srv_src', 'sttl', 'dttl', 'tcprtt', 'ct_srv_dst', 'ct_src_dport_ltm', 'ct_dst_src_ltm', 'dmeansz', 'Sload', 'Djit', 'dwin', 'ackdat', 'Sintpkt', 'ct_dst_ltm', 'sloss', 'ct_flw_http_mthd', 'Sjit', 'res_bdy_len', 'smeansz', 'sbytes', 'Dpkts', 'trans_depth', 'dur', 'dbytes', 'stcpb', 'ct_src_ ltm', 'swin']\n",
      "+------+-------+\n",
      "|target|  count|\n",
      "+------+-------+\n",
      "|   YES|  19195|\n",
      "|    NO|2520852|\n",
      "+------+-------+\n",
      "\n",
      "None"
     ]
    }
   ],
   "source": [
    "print(list_of_columns)\n",
    "print(df_nulls.groupBy('target').count().show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Woe and IV for continuous columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+-----+----+\n",
      "|ct_dst_sport_ltm_bin| NO_%|YES_%|  WoE|  IV|\n",
      "+--------------------+-----+-----+-----+----+\n",
      "|                 1,1| 77.5|82.37|-0.06| 0.0|\n",
      "|                2,14|12.45|17.63|-0.35|0.02|\n",
      "|               15,60|10.05|  0.0| null|null|\n",
      "+--------------------+-----+-----+-----+----+\n",
      "\n",
      "Variable  ct_dst_sport_ltm  total Information Value =>  0.02\n",
      "+---------+-----+-----+-----+----+\n",
      "|dloss_bin| NO_%|YES_%|  WoE|  IV|\n",
      "+---------+-----+-----+-----+----+\n",
      "|      0,3|48.17| 93.8|-0.67| 0.3|\n",
      "|      4,4| 6.65| 5.14| 0.26| 0.0|\n",
      "|      5,7|12.57| 0.79| 2.76|0.33|\n",
      "|     8,15|11.85| 0.14| 4.43|0.52|\n",
      "|    16,26|10.11| 0.04| 5.62|0.57|\n",
      "|  27,5507|10.65| 0.09| 4.73| 0.5|\n",
      "+---------+-----+-----+-----+----+\n",
      "\n",
      "Variable  dloss  total Information Value =>  2.2199999999999998\n",
      "+--------------------+-----+-----+-----+----+\n",
      "|         Dintpkt_bin| NO_%|YES_%|  WoE|  IV|\n",
      "+--------------------+-----+-----+-----+----+\n",
      "|59.08359100000000...| 9.57|56.95|-1.78|0.84|\n",
      "|0.415412,0.827545...|10.05|  0.0| null|null|\n",
      "|12.26423500000000...|10.04| 7.55| 0.28|0.01|\n",
      "|      0.008,0.261935|11.36| 0.04| 5.74|0.65|\n",
      "|   0.261941,0.415411|10.07|  0.0| null|null|\n",
      "|  1.769826,12.264201|10.08| 0.01| 6.87|0.69|\n",
      "|0.001,0.006999999...| 9.14| 0.07| 4.83|0.44|\n",
      "|   0.827548,1.769811| 10.1|  0.0| null|null|\n",
      "|             0.0,0.0|19.59|35.38|-0.59|0.09|\n",
      "+--------------------+-----+-----+-----+----+\n",
      "\n",
      "Variable  Dintpkt  total Information Value =>  2.7199999999999998\n",
      "+--------------------+-----+-----+-----+----+\n",
      "|           Dload_bin| NO_%|YES_%|  WoE|  IV|\n",
      "+--------------------+-----+-----+-----+----+\n",
      "|678741.6875,11684...| 10.1|  0.0| null|null|\n",
      "| 3931544.5,9985399.0|10.01|  0.0| null|null|\n",
      "|592321.8125,67874...| 10.0| 0.01| 7.56|0.76|\n",
      "|103554.1875,59231...|10.14| 0.09| 4.74|0.48|\n",
      "|50576.75,103554.0313| 10.1| 0.06| 5.17|0.52|\n",
      "|9985414.0,1.28761...|10.09|  0.0| null|null|\n",
      "|      0.0,586.623291|19.94|37.66|-0.64|0.11|\n",
      "|1168481.75,393153...|10.06| 0.01| 7.57|0.76|\n",
      "|586.930603,50576....| 9.56|62.18|-1.87|0.99|\n",
      "+--------------------+-----+-----+-----+----+\n",
      "\n",
      "Variable  Dload  total Information Value =>  3.6199999999999997\n",
      "+---------+-----+-----+-----+----+\n",
      "|Spkts_bin| NO_%|YES_%|  WoE|  IV|\n",
      "+---------+-----+-----+-----+----+\n",
      "|      0,1|  0.2| 0.08| 0.87| 0.0|\n",
      "|      2,3|34.01|32.08| 0.06| 0.0|\n",
      "|     4,11|13.43|29.73|-0.79|0.13|\n",
      "|    12,17| 12.2|25.17|-0.72|0.09|\n",
      "|    18,37| 9.69| 6.17| 0.45|0.02|\n",
      "|    38,51| 9.68| 0.73| 2.59|0.23|\n",
      "|    52,67|10.69| 3.59| 1.09|0.08|\n",
      "| 68,10646| 10.1| 2.45| 1.42|0.11|\n",
      "+---------+-----+-----+-----+----+\n",
      "\n",
      "Variable  Spkts  total Information Value =>  0.66\n",
      "+--------------------+-----+-----+-----+----+\n",
      "|          synack_bin| NO_%|YES_%|  WoE|  IV|\n",
      "+--------------------+-----+-----+-----+----+\n",
      "|      5.42E-4,5.7E-4|10.26|  0.0| null|null|\n",
      "|6.259999999999999...| 9.56|64.45|-1.91|1.05|\n",
      "|     5.19E-4,5.41E-4| 9.79|  0.0| null|null|\n",
      "|0.0,4.83000000000...|50.19|35.55| 0.35|0.05|\n",
      "|     4.84E-4,5.18E-4|10.03|  0.0| null|null|\n",
      "|     5.71E-4,6.25E-4|10.17|  0.0| null|null|\n",
      "+--------------------+-----+-----+-----+----+\n",
      "\n",
      "Variable  synack  total Information Value =>  1.1\n",
      "+--------------+-----+-----+-----+----+\n",
      "|ct_srv_src_bin| NO_%|YES_%|  WoE|  IV|\n",
      "+--------------+-----+-----+-----+----+\n",
      "|           1,1|14.34| 8.38| 0.54|0.03|\n",
      "|           2,2|12.67|16.23|-0.25|0.01|\n",
      "|           3,3|11.76|16.59|-0.34|0.02|\n",
      "|           4,4|  7.7|13.56|-0.57|0.03|\n",
      "|           5,6|12.56| 19.7|-0.45|0.03|\n",
      "|           7,8| 9.27|10.45|-0.12| 0.0|\n",
      "|          9,12|10.78| 9.27| 0.15| 0.0|\n",
      "|         13,26|10.82|  3.4| 1.16|0.09|\n",
      "|         27,67| 10.1| 2.42| 1.43|0.11|\n",
      "+--------------+-----+-----+-----+----+\n",
      "\n",
      "Variable  ct_srv_src  total Information Value =>  0.31999999999999995\n",
      "+--------+-----+-----+-----+----+\n",
      "|sttl_bin| NO_%|YES_%|  WoE|  IV|\n",
      "+--------+-----+-----+-----+----+\n",
      "|    0,30| 0.71| 0.08| 2.21|0.01|\n",
      "|   31,32|77.05|  0.0| null|null|\n",
      "|  60,252| 9.85| 0.29| 3.54|0.34|\n",
      "| 254,255|12.39|99.64|-2.08|1.82|\n",
      "+--------+-----+-----+-----+----+\n",
      "\n",
      "Variable  sttl  total Information Value =>  2.17\n",
      "+--------+-----+-----+-----+----+\n",
      "|dttl_bin| NO_%|YES_%|  WoE|  IV|\n",
      "+--------+-----+-----+-----+----+\n",
      "|     0,0|19.81|35.38|-0.58|0.09|\n",
      "|  29,254|80.19|64.62| 0.22|0.03|\n",
      "+--------+-----+-----+-----+----+\n",
      "\n",
      "Variable  dttl  total Information Value =>  0.12\n",
      "+--------------------+-----+-----+-----+----+\n",
      "|          tcprtt_bin| NO_%|YES_%|  WoE|  IV|\n",
      "+--------------------+-----+-----+-----+----+\n",
      "|     6.85E-4,7.21E-4| 9.93|  0.0| null|null|\n",
      "|   7.96E-4,10.037506| 9.55|64.45|-1.91|1.05|\n",
      "|6.14E-4,6.5199999...|  9.9|  0.0| null|null|\n",
      "|     7.22E-4,7.95E-4|10.18|  0.0| null|null|\n",
      "|0.0,6.12999999999...|50.17|35.55| 0.34|0.05|\n",
      "|     6.53E-4,6.84E-4|10.26|  0.0| null|null|\n",
      "+--------------------+-----+-----+-----+----+\n",
      "\n",
      "Variable  tcprtt  total Information Value =>  1.1\n",
      "+--------------+-----+-----+-----+----+\n",
      "|ct_srv_dst_bin| NO_%|YES_%|  WoE|  IV|\n",
      "+--------------+-----+-----+-----+----+\n",
      "|           1,1|14.85|12.23| 0.19|0.01|\n",
      "|           2,2|12.69| 20.8|-0.49|0.04|\n",
      "|           3,3|12.12|18.15| -0.4|0.02|\n",
      "|           4,4| 8.24|12.63|-0.43|0.02|\n",
      "|           5,5| 6.97| 9.65|-0.33|0.01|\n",
      "|           6,7| 11.2|10.85| 0.03| 0.0|\n",
      "|          8,11|12.49| 9.21|  0.3|0.01|\n",
      "|         12,26|11.41| 4.13| 1.02|0.07|\n",
      "|         27,67|10.04| 2.35| 1.45|0.11|\n",
      "+--------------+-----+-----+-----+----+\n",
      "\n",
      "Variable  ct_srv_dst  total Information Value =>  0.29000000000000004\n",
      "+--------------------+-----+-----+----+----+\n",
      "|ct_src_dport_ltm_bin| NO_%|YES_%| WoE|  IV|\n",
      "+--------------------+-----+-----+----+----+\n",
      "|                 1,1|66.66| 56.8|0.16|0.02|\n",
      "|                 2,3|12.25|33.44|-1.0|0.21|\n",
      "|                4,16|10.59| 9.64|0.09| 0.0|\n",
      "|               17,67|10.51| 0.12|4.47|0.46|\n",
      "+--------------------+-----+-----+----+----+\n",
      "\n",
      "Variable  ct_src_dport_ltm  total Information Value =>  0.6900000000000001\n",
      "+------------------+-----+-----+-----+----+\n",
      "|ct_dst_src_ltm_bin| NO_%|YES_%|  WoE|  IV|\n",
      "+------------------+-----+-----+-----+----+\n",
      "|               1,1|40.07|13.29|  1.1| 0.3|\n",
      "|               2,2| 16.9|22.64|-0.29|0.02|\n",
      "|               3,3| 11.4|18.73| -0.5|0.04|\n",
      "|               4,5| 9.77|20.85|-0.76|0.08|\n",
      "|              6,25|11.38|21.88|-0.65|0.07|\n",
      "|             26,67|10.48| 2.61| 1.39|0.11|\n",
      "+------------------+-----+-----+-----+----+\n",
      "\n",
      "Variable  ct_dst_src_ltm  total Information Value =>  0.6200000000000001\n",
      "+-----------+-----+-----+-----+----+\n",
      "|dmeansz_bin| NO_%|YES_%|  WoE|  IV|\n",
      "+-----------+-----+-----+-----+----+\n",
      "|       0,43|19.95|36.14|-0.59| 0.1|\n",
      "|      44,77| 9.81| 45.8|-1.54|0.55|\n",
      "|      78,81| 8.41| 3.63| 0.84|0.04|\n",
      "|      82,88|  2.8| 5.83|-0.73|0.02|\n",
      "|     89,122|18.16| 8.05| 0.81|0.08|\n",
      "|    123,439| 10.7| 0.34| 3.44|0.36|\n",
      "|    440,564| 4.19| 0.08| 3.98|0.16|\n",
      "|    565,754|15.98| 0.01| 7.34|1.17|\n",
      "|   755,1500| 9.99| 0.11| 4.51|0.45|\n",
      "+-----------+-----+-----+-----+----+\n",
      "\n",
      "Variable  dmeansz  total Information Value =>  2.9299999999999997\n",
      "+--------------------+-----+-----+-----+----+\n",
      "|           Sload_bin| NO_%|YES_%|  WoE|  IV|\n",
      "+--------------------+-----+-----+-----+----+\n",
      "|1672232.5,1.14063...|10.04| 0.01| 6.87|0.69|\n",
      "|899393.9375,16721...| 10.1| 0.17|  4.1|0.41|\n",
      "|0.0,11986.9365200...|  9.8|43.59|-1.49| 0.5|\n",
      "|  1.1406639E7,1.17E8| 9.04|12.72|-0.34|0.01|\n",
      "|1.17333328E8,5.98...|10.87| 19.3|-0.57|0.05|\n",
      "|590173.625,899392...|10.01|  1.0| 2.31|0.21|\n",
      "|313164.9375,52612...|10.07| 2.39| 1.44|0.11|\n",
      "|526126.125,590172...|10.07| 0.48| 3.03|0.29|\n",
      "|61706.06641,31316...| 10.0| 4.37| 0.83|0.05|\n",
      "|11986.94727,61706...| 9.99|15.97|-0.47|0.03|\n",
      "+--------------------+-----+-----+-----+----+\n",
      "\n",
      "Variable  Sload  total Information Value =>  2.3499999999999996\n",
      "+--------------------+-----+-----+-----+----+\n",
      "|            Djit_bin| NO_%|YES_%|  WoE|  IV|\n",
      "+--------------------+-----+-----+-----+----+\n",
      "|20.64291099999999...|10.03| 0.13| 4.38|0.43|\n",
      "|1452.650298,78122...|10.01| 4.26| 0.85|0.05|\n",
      "|   0.407727,2.769239|10.16|  0.0| null|null|\n",
      "|        0.0,0.407724|40.05| 35.5| 0.12|0.01|\n",
      "|91.002758,1452.62...| 9.74|51.63|-1.67| 0.7|\n",
      "|2.769262,20.64289...|10.08|  0.0| null|null|\n",
      "|  39.452317,91.00274| 9.94| 8.49| 0.16| 0.0|\n",
      "+--------------------+-----+-----+-----+----+\n",
      "\n",
      "Variable  Djit  total Information Value =>  1.19\n",
      "+--------+-----+-----+-----+----+\n",
      "|dwin_bin| NO_%|YES_%|  WoE|  IV|\n",
      "+--------+-----+-----+-----+----+\n",
      "|   0,253|41.32|35.54| 0.15|0.01|\n",
      "| 255,255|58.68|64.46|-0.09|0.01|\n",
      "+--------+-----+-----+-----+----+\n",
      "\n",
      "Variable  dwin  total Information Value =>  0.02\n",
      "+--------------------+-----+-----+-----+----+\n",
      "|          ackdat_bin| NO_%|YES_%|  WoE|  IV|\n",
      "+--------------------+-----+-----+-----+----+\n",
      "|     1.22E-4,1.28E-4|10.07|  0.0| null|null|\n",
      "|1.629999999999999...| 9.77|64.45|-1.89|1.03|\n",
      "|1.370000000000000...| 9.69|  0.0| null|null|\n",
      "|     1.46E-4,1.62E-4|10.15|  0.0| null|null|\n",
      "|     1.29E-4,1.36E-4|10.86|  0.0| null|null|\n",
      "|         0.0,1.21E-4|49.46|35.55| 0.33|0.05|\n",
      "+--------------------+-----+-----+-----+----+\n",
      "\n",
      "Variable  ackdat  total Information Value =>  1.08\n",
      "+--------------------+-----+-----+-----+----+\n",
      "|         Sintpkt_bin| NO_%|YES_%|  WoE|  IV|\n",
      "+--------------------+-----+-----+-----+----+\n",
      "|   0.331974,0.470135|10.11|  0.0| null|null|\n",
      "|         0.005,0.008|10.35| 9.71| 0.06| 0.0|\n",
      "|   0.962922,2.415571| 10.1|  0.0| null|null|\n",
      "|    14.519,71.588889| 9.75|31.73|-1.18|0.26|\n",
      "|0.011000000000000...| 10.5| 2.21| 1.56|0.13|\n",
      "|        0.0,0.004667| 8.63| 9.32|-0.08| 0.0|\n",
      "|0.009000000000000...|10.65|10.53| 0.01| 0.0|\n",
      "| 71.589457,84371.496| 9.79|35.55|-1.29|0.33|\n",
      "|2.415578,14.51897...|10.07| 0.95| 2.36|0.22|\n",
      "|0.470135999999999...|10.04|  0.0| null|null|\n",
      "+--------------------+-----+-----+-----+----+\n",
      "\n",
      "Variable  Sintpkt  total Information Value =>  0.9400000000000001\n",
      "+--------------+-----+-----+-----+----+\n",
      "|ct_dst_ltm_bin| NO_%|YES_%|  WoE|  IV|\n",
      "+--------------+-----+-----+-----+----+\n",
      "|           1,1| 14.8|49.48|-1.21|0.42|\n",
      "|           2,2|18.79|27.57|-0.38|0.03|\n",
      "|           3,3|16.51| 9.77| 0.52|0.04|\n",
      "|           4,4|12.36| 3.44| 1.28|0.11|\n",
      "|           5,7|16.82| 3.25| 1.65|0.22|\n",
      "|          8,17|10.57| 5.39| 0.67|0.03|\n",
      "|         18,67|10.15|  1.1| 2.22| 0.2|\n",
      "+--------------+-----+-----+-----+----+\n",
      "\n",
      "Variable  ct_dst_ltm  total Information Value =>  1.05\n",
      "+---------+-----+-----+-----+----+\n",
      "|sloss_bin| NO_%|YES_%|  WoE|  IV|\n",
      "+---------+-----+-----+-----+----+\n",
      "|      0,2| 48.9|64.75|-0.28|0.04|\n",
      "|      3,3| 6.35|17.97|-1.04|0.12|\n",
      "|      4,6| 9.06| 8.36| 0.08| 0.0|\n",
      "|     7,10|24.78| 2.09| 2.47|0.56|\n",
      "|  11,5319|10.91| 6.83| 0.47|0.02|\n",
      "+---------+-----+-----+-----+----+\n",
      "\n",
      "Variable  sloss  total Information Value =>  0.7400000000000001\n",
      "+--------------------+-----+-----+-----+----+\n",
      "|ct_flw_http_mthd_bin| NO_%|YES_%|  WoE|  IV|\n",
      "+--------------------+-----+-----+-----+----+\n",
      "|         -99.0,-99.0|52.76|94.39|-0.58|0.24|\n",
      "|            0.0,36.0|47.24| 5.61| 2.13|0.89|\n",
      "+--------------------+-----+-----+-----+----+\n",
      "\n",
      "Variable  ct_flw_http_mthd  total Information Value =>  1.13\n",
      "+--------------------+-----+-----+-----+----+\n",
      "|            Sjit_bin| NO_%|YES_%|  WoE|  IV|\n",
      "+--------------------+-----+-----+-----+----+\n",
      "| 19.240311,35.672472| 9.99| 0.06| 5.07| 0.5|\n",
      "|0.651481000000000...|10.11| 0.01| 7.57|0.77|\n",
      "|837.985395,4536.1...| 9.82|37.14|-1.33|0.36|\n",
      "|0.0,0.65124799999...|40.14|31.84| 0.23|0.02|\n",
      "|4536.179904,14838...|  9.8|29.54| -1.1|0.22|\n",
      "|35.672578,94.2080...|10.18| 0.27| 3.65|0.36|\n",
      "| 94.20823,837.982513| 9.96| 1.15| 2.16|0.19|\n",
      "+--------------------+-----+-----+-----+----+\n",
      "\n",
      "Variable  Sjit  total Information Value =>  2.4200000000000004\n",
      "+---------------+-----+-----+---+---+\n",
      "|res_bdy_len_bin| NO_%|YES_%|WoE| IV|\n",
      "+---------------+-----+-----+---+---+\n",
      "|      0,6558056|100.0|100.0|0.0|0.0|\n",
      "+---------------+-----+-----+---+---+\n",
      "\n",
      "Variable  res_bdy_len  total Information Value =>  0.0\n",
      "+-----------+-----+-----+-----+----+\n",
      "|smeansz_bin| NO_%|YES_%|  WoE|  IV|\n",
      "+-----------+-----+-----+-----+----+\n",
      "|       0,56|  8.8|23.99| -1.0|0.15|\n",
      "|      57,57| 9.57| 2.55| 1.32|0.09|\n",
      "|      58,61| 9.33| 4.59| 0.71|0.03|\n",
      "|      62,64|11.36| 1.11| 2.32|0.24|\n",
      "|      65,72| 7.55| 2.09| 1.28|0.07|\n",
      "|      73,86|12.95|11.75|  0.1| 0.0|\n",
      "|     87,119| 8.09|19.21|-0.87| 0.1|\n",
      "|    120,131| 5.28| 1.78| 1.09|0.04|\n",
      "|    132,151|17.29|  1.1| 2.76|0.45|\n",
      "|   152,1504| 9.79|31.82|-1.18|0.26|\n",
      "+-----------+-----+-----+-----+----+\n",
      "\n",
      "Variable  smeansz  total Information Value =>  1.43\n",
      "+-------------+-----+-----+-----+----+\n",
      "|   sbytes_bin| NO_%|YES_%|  WoE|  IV|\n",
      "+-------------+-----+-----+-----+----+\n",
      "|        0,128| 8.94|10.01|-0.11| 0.0|\n",
      "|      130,144| 4.59| 0.06| 4.38| 0.2|\n",
      "|      146,262|12.03| 9.75| 0.21| 0.0|\n",
      "|      264,532|14.56| 3.72| 1.36|0.15|\n",
      "|     534,1468| 9.12|50.08| -1.7| 0.7|\n",
      "|    1470,2046|10.52| 6.23| 0.52|0.02|\n",
      "|    2048,2852| 9.34|  5.3| 0.57|0.02|\n",
      "|    2854,3823| 10.9| 2.74| 1.38|0.11|\n",
      "|    3824,7816|10.05| 1.96| 1.64|0.13|\n",
      "|7818,14355774| 9.96|10.15|-0.02| 0.0|\n",
      "+-------------+-----+-----+-----+----+\n",
      "\n",
      "Variable  sbytes  total Information Value =>  1.33\n",
      "+---------+-----+-----+-----+----+\n",
      "|Dpkts_bin| NO_%|YES_%|  WoE|  IV|\n",
      "+---------+-----+-----+-----+----+\n",
      "|      0,1|19.59|35.38|-0.59|0.09|\n",
      "|      2,3| 15.3| 0.11| 4.94|0.75|\n",
      "|     4,11|13.08|49.62|-1.33|0.49|\n",
      "|    12,17| 3.95|12.93|-1.18|0.11|\n",
      "|    18,37|17.07| 1.79| 2.25|0.34|\n",
      "|    38,47| 10.1| 0.02| 6.47|0.65|\n",
      "|    48,67|10.23| 0.03| 5.79|0.59|\n",
      "| 68,11018|10.67| 0.13| 4.45|0.47|\n",
      "+---------+-----+-----+-----+----+\n",
      "\n",
      "Variable  Dpkts  total Information Value =>  3.4899999999999998\n",
      "+---------------+-----+-----+---+---+\n",
      "|trans_depth_bin| NO_%|YES_%|WoE| IV|\n",
      "+---------------+-----+-----+---+---+\n",
      "|          0,172|100.0|100.0|0.0|0.0|\n",
      "+---------------+-----+-----+---+---+\n",
      "\n",
      "Variable  trans_depth  total Information Value =>  0.0\n",
      "+--------------------+-----+-----+-----+----+\n",
      "|             dur_bin| NO_%|YES_%|  WoE|  IV|\n",
      "+--------------------+-----+-----+-----+----+\n",
      "|   0.393828,1.050409| 9.83|35.44|-1.28|0.33|\n",
      "|          0.0,6.0E-6| 8.98| 14.0|-0.44|0.02|\n",
      "|9.539999999999999...|10.11|  0.0| null|null|\n",
      "|   0.001082,0.004646|10.06|  0.0| null|null|\n",
      "|1.050418,8786.637695| 9.86|27.27|-1.02|0.18|\n",
      "|   0.031658,0.085024|10.15| 0.01| 6.88| 0.7|\n",
      "|   0.085025,0.393826| 9.91| 5.14| 0.66|0.03|\n",
      "|7.000000000000001...|10.96|18.13| -0.5|0.04|\n",
      "|   0.004647,0.015895|10.12|  0.0| null|null|\n",
      "|   0.015896,0.031657|10.02|  0.0| null|null|\n",
      "+--------------------+-----+-----+-----+----+\n",
      "\n",
      "Variable  dur  total Information Value =>  1.3\n",
      "+--------------+-----+-----+-----+----+\n",
      "|    dbytes_bin| NO_%|YES_%|  WoE|  IV|\n",
      "+--------------+-----+-----+-----+----+\n",
      "|         0,110|19.95|35.41|-0.57|0.09|\n",
      "|       112,176| 4.72| 0.01| 6.12|0.29|\n",
      "|       178,310|15.19|18.71|-0.21|0.01|\n",
      "|      312,1828| 9.82|45.54|-1.53|0.55|\n",
      "|     1830,3378| 9.51|  0.1| 4.56|0.43|\n",
      "|    3380,10167| 7.89| 0.09| 4.43|0.35|\n",
      "|   10168,22106|12.74| 0.04| 5.72|0.73|\n",
      "|   22128,45394|10.17|  0.0| null|null|\n",
      "|45396,14657531|10.02|  0.1| 4.62|0.46|\n",
      "+--------------+-----+-----+-----+----+\n",
      "\n",
      "Variable  dbytes  total Information Value =>  2.9099999999999993\n",
      "+--------------------+-----+-----+-----+---+\n",
      "|           stcpb_bin| NO_%|YES_%|  WoE| IV|\n",
      "+--------------------+-----+-----+-----+---+\n",
      "|         0,639740920|50.04|45.19|  0.1|0.0|\n",
      "|639742606,1374336405|10.05|11.28|-0.12|0.0|\n",
      "|1374343456,210623...|10.01|11.29|-0.12|0.0|\n",
      "|2106239603,284533...|10.07|10.85|-0.07|0.0|\n",
      "|2845347994,356584...| 9.84|10.51|-0.07|0.0|\n",
      "|3565843027,429495...| 10.0|10.88|-0.08|0.0|\n",
      "+--------------------+-----+-----+-----+---+\n",
      "\n",
      "Variable  stcpb  total Information Value =>  0.0\n",
      "+---------------+-----+-----+-----+----+\n",
      "|ct_src_ ltm_bin| NO_%|YES_%|  WoE|  IV|\n",
      "+---------------+-----+-----+-----+----+\n",
      "|            1,1|11.98|36.13| -1.1|0.27|\n",
      "|            2,2|16.82| 29.3|-0.55|0.07|\n",
      "|            3,3|15.52|14.13| 0.09| 0.0|\n",
      "|            4,4|12.08| 5.59| 0.77|0.05|\n",
      "|            5,5| 9.09| 2.69| 1.22|0.08|\n",
      "|            6,8|13.64| 3.52| 1.35|0.14|\n",
      "|           9,17|10.24| 5.28| 0.66|0.03|\n",
      "|          18,67|10.63| 3.35| 1.15|0.08|\n",
      "+---------------+-----+-----+-----+----+\n",
      "\n",
      "Variable  ct_src_ ltm  total Information Value =>  0.72\n",
      "+--------+-----+-----+-----+----+\n",
      "|swin_bin| NO_%|YES_%|  WoE|  IV|\n",
      "+--------+-----+-----+-----+----+\n",
      "|   0,245|41.19|35.54| 0.15|0.01|\n",
      "| 255,255|58.81|64.46|-0.09|0.01|\n",
      "+--------+-----+-----+-----+----+\n",
      "\n",
      "Variable  swin  total Information Value =>  0.02"
     ]
    }
   ],
   "source": [
    "# the function woe will print the results of WoE and IV calculations for each variable(predictor).\n",
    "# each continuous column is transformed into categorical with QuantileDiscretizer function, \n",
    "# the output of which is 10 equaly distributed bins/value-ranges including \"missing\" category for null values \n",
    "# WoE and IV are calculated for each bin value\n",
    "\n",
    "# the list total_iv_list will be populated with total IV (sum of bins IV) of a variable.\n",
    "# the list variable_list will be populated with the names of variables\n",
    "\n",
    "def woe(main_df, d, numbuck=10, limit=-99, list_of_columns=list):\n",
    "    variable_list=[]\n",
    "    total_iv_list=[]\n",
    "    nan=int(limit)\n",
    "    nan_bin=str(nan)+','+str(nan)\n",
    "    n=int(main_df.groupBy('target').count().collect()[1][1])\n",
    "    y=int(main_df.groupBy('target').count().collect()[0][1])\n",
    "    for predictor in list_of_columns:\n",
    "        predictor_range=predictor+'_range'\n",
    "        predictor_bin=predictor+'_bin'\n",
    "        # binning\n",
    "        df = QuantileDiscretizer(numBuckets=numbuck, inputCol=predictor,outputCol=predictor_range).fit(main_df).transform(main_df)\n",
    "        df=df.fillna(nan, subset=[predictor, predictor_range])\n",
    "        df_gr = df.groupBy(predictor_range) \\\n",
    "            .agg(F.min(predictor).alias(\"min\"),F.max(predictor).alias(\"max\")) \\\n",
    "            .withColumn(predictor_bin,F.concat(F.col(\"min\"),F.lit(\",\"),F.col(\"max\")))  \\\n",
    "            .withColumn(predictor_bin, regexp_replace(predictor_bin, nan_bin, 'missing'))\n",
    "        df_gr=df_gr.drop('min', 'max')\n",
    "        df=df.join(df_gr, predictor_range, 'left').drop(predictor_range)\n",
    "        d = df.select('PK_column', predictor_bin).join(d, df.PK_column == d.PK_column, 'left').drop(d.PK_column)\n",
    "        # WoE calculation\n",
    "        df = df.crosstab(predictor_bin,'target')\n",
    "        variable_list.append(predictor)\n",
    "        df = df.withColumn(\"YES_%\",(F.col(\"YES\")/y))\n",
    "        df = df.withColumn(\"NO_%\",(F.col(\"NO\")/n))\n",
    "        df = df.withColumn(\"WoE\", F.log(F.col(\"NO_%\")/F.col(\"YES_%\")))\n",
    "        df = df.withColumn(\"IV\", F.log(F.col(\"NO_%\") / F.col(\"YES_%\")) * (F.col(\"NO_%\") - F.col(\"YES_%\")))\n",
    "        df = df.withColumnRenamed(df.columns[0],predictor_bin)\n",
    "        df=df.withColumn('order', regexp_replace(predictor_bin, \",-\", '.'))\n",
    "        df= df.withColumn('order', regexp_replace(\"order\", \",\", '.'))\n",
    "        df = df.withColumn(\"order\", df[\"order\"].cast(DoubleType()))\n",
    "        df = df.orderBy(\"order\")\n",
    "        df=df.withColumn(\"WoE\",  F.round(df[\"WoE\"], 2)).withColumn(\"IV\",  F.round(df[\"IV\"], 2))\n",
    "        df=df.withColumn(\"NO_%\",  F.round(df[\"NO_%\"]*100, 2)).withColumn(\"YES_%\",  F.round(df[\"YES_%\"]*100, 2))\n",
    "        df=df.select(predictor_bin, 'NO_%', 'YES_%', 'WoE', 'IV')\n",
    "        df.show()\n",
    "        iv_sum = df.groupBy().sum().select(\"sum(IV)\").collect()[0][0]\n",
    "        print('Variable ', predictor, ' total Information Value => ', iv_sum)\n",
    "        total_iv_list.append(iv_sum)\n",
    "    return d, variable_list, total_iv_list\n",
    "\n",
    "\n",
    "d, variable_list, total_iv_list = woe(df_nulls, d, list_of_columns=list_of_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns to drop IV < 0.1 ['ct_dst_sport_ltm', 'dwin', 'res_bdy_len', 'stcpb', 'swin', 'trans_depth']\n",
      "Top 10 columns ['Dload' 'Dpkts' 'dmeansz' 'dbytes' 'Dintpkt' 'Sjit' 'Sload' 'dloss'\n",
      " 'sttl' 'smeansz']"
     ]
    }
   ],
   "source": [
    "# Information value filter\n",
    "\n",
    "# create pandas dataframe with variable names and their IV values\n",
    "tuples=list(zip(variable_list, total_iv_list))\n",
    "IV_pandasDF=pd.DataFrame(tuples, columns=['variable_name', 'IV'])\n",
    "IV_pandasDF.sort_values('IV', ascending=False).head(20)\n",
    "\n",
    "# The function to print the columns with IV lower than 0.1, that is, attributes that have low predictive power\n",
    "def iv_check(variable_list, total_iv_list):\n",
    "    tuples=list(zip(variable_list, total_iv_list))\n",
    "    IV_pandasDF=pd.DataFrame(tuples, columns=['variable_name', 'IV'])\n",
    "    IV_pandasDF=IV_pandasDF.sort_values('IV', ascending=False)\n",
    "    to_drop=[]\n",
    "    top10=IV_pandasDF.variable_name.values[:10]\n",
    "    for i in range(IV_pandasDF.count()[0]):\n",
    "        if IV_pandasDF.iloc[i,1]<0.1:\n",
    "            column_to_drop=IV_pandasDF.iloc[i,0]\n",
    "            to_drop.append(column_to_drop)\n",
    "    print(\"Columns to drop IV < 0.1 {}\".format(sorted(to_drop)))\n",
    "    print(\"Top 10 columns {}\".format(top10))\n",
    "    print()\n",
    "    return list(top10)\n",
    "\n",
    "top_10_list=iv_check(variable_list, total_iv_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Woe and IV for categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----+-----+-----+----+\n",
      "|     dstip_bin|NO_%|YES_%|  WoE|  IV|\n",
      "+--------------+----+-----+-----+----+\n",
      "| 149.171.126.2|7.84|  0.0| null|null|\n",
      "| 149.171.126.7|7.55|  0.0| null|null|\n",
      "|149.171.126.12|1.15| 7.38|-1.86|0.12|\n",
      "| 149.171.126.8|7.44|  0.0| null|null|\n",
      "| 149.171.126.1|7.84|  0.0| null|null|\n",
      "|149.171.126.15|1.94|10.39|-1.68|0.14|\n",
      "| 149.171.126.4|7.84|  0.0| null|null|\n",
      "|149.171.126.10|1.65|12.26| -2.0|0.21|\n",
      "| 149.171.126.5|7.81|  0.0| null|null|\n",
      "| 149.171.126.0|7.81|  0.0| null|null|\n",
      "|149.171.126.14|1.72|11.45| -1.9|0.18|\n",
      "|149.171.126.17|0.98|11.59|-2.47|0.26|\n",
      "| 149.171.126.9|7.56|  0.0| null|null|\n",
      "| 149.171.126.6|7.53|  0.0| null|null|\n",
      "| 149.171.126.3|7.85|  0.0| null|null|\n",
      "|  175.45.176.0|1.85|  0.0| null|null|\n",
      "|149.171.126.18|4.04|  5.8|-0.36|0.01|\n",
      "|  175.45.176.1|2.93|  0.0| null|null|\n",
      "|         other|2.96|41.13|-2.63| 1.0|\n",
      "|  175.45.176.3|3.72|  0.0| null|null|\n",
      "+--------------+----+-----+-----+----+\n",
      "\n",
      "Variable  dstip  total Information Value =>  1.92\n",
      "+---------+-----+-----+-----+----+\n",
      "|sport_bin| NO_%|YES_%|  WoE|  IV|\n",
      "+---------+-----+-----+-----+----+\n",
      "|    47439| 8.06|  0.0| null|null|\n",
      "|     1043| 8.74|  0.0| null|null|\n",
      "|        0| 2.07| 9.06|-1.47| 0.1|\n",
      "|    other|81.12|90.94|-0.11|0.01|\n",
      "+---------+-----+-----+-----+----+\n",
      "\n",
      "Variable  sport  total Information Value =>  0.11\n",
      "+----------+-----+-----+-----+----+\n",
      "|dsport_bin| NO_%|YES_%|  WoE|  IV|\n",
      "+----------+-----+-----+-----+----+\n",
      "|        22| 2.02|  0.0| null|null|\n",
      "|        21| 1.98| 2.91|-0.38| 0.0|\n",
      "|      6881| 4.96|  0.0| null|null|\n",
      "|        80| 8.94| 6.49| 0.32|0.01|\n",
      "|        25| 3.52|  0.0| null|null|\n",
      "|       111|  3.7|  0.0| null|null|\n",
      "|        53|31.69|  0.0| null|null|\n",
      "|         0| 2.08| 9.06|-1.47| 0.1|\n",
      "|      5190| 4.78|  0.0| null|null|\n",
      "|       143| 2.03|  0.0| null|null|\n",
      "|     other|34.29|81.55|-0.87|0.41|\n",
      "+----------+-----+-----+-----+----+\n",
      "\n",
      "Variable  dsport  total Information Value =>  0.52\n",
      "+----------------+-----+-----+-----+----+\n",
      "|ct_state_ttl_bin| NO_%|YES_%|  WoE|  IV|\n",
      "+----------------+-----+-----+-----+----+\n",
      "|               4|  0.0|  0.0| null|null|\n",
      "|               5|  0.0|  0.0| null|null|\n",
      "|               6| 0.15| 1.79|-2.47|0.04|\n",
      "|               1| 2.74|64.45|-3.16|1.95|\n",
      "|               0|86.41| 0.17| 6.22|5.36|\n",
      "|               2|10.53|33.59|-1.16|0.27|\n",
      "|               3| 0.17|  0.0| null|null|\n",
      "+----------------+-----+-----+-----+----+\n",
      "\n",
      "Variable  ct_state_ttl  total Information Value =>  7.620000000000001\n",
      "+--------------+----+-----+-----+----+\n",
      "|     srcip_bin|NO_%|YES_%|  WoE|  IV|\n",
      "+--------------+----+-----+-----+----+\n",
      "|    59.166.0.9|7.54|  0.0| null|null|\n",
      "|  175.45.176.2|1.08| 24.5|-3.12|0.73|\n",
      "|    59.166.0.2|7.84|  0.0| null|null|\n",
      "|    59.166.0.8|7.51|  0.0| null|null|\n",
      "|    59.166.0.3|7.77|  0.0| null|null|\n",
      "|149.171.126.15|1.78|  0.0| null|null|\n",
      "|    59.166.0.0|7.84|  0.0| null|null|\n",
      "|149.171.126.10| 1.2|  0.0| null|null|\n",
      "|    59.166.0.4|7.85|  0.0| null|null|\n",
      "|149.171.126.14|1.63|  0.0| null|null|\n",
      "|    59.166.0.7| 7.5|  0.0| null|null|\n",
      "|    59.166.0.1|7.84|  0.0| null|null|\n",
      "|    59.166.0.6|7.51|  0.0| null|null|\n",
      "|  175.45.176.0|3.09| 26.1|-2.13|0.49|\n",
      "|149.171.126.18|3.24|  0.0| null|null|\n",
      "|  175.45.176.1|4.87| 27.0|-1.71|0.38|\n",
      "|         other|1.51|  0.0| null|null|\n",
      "|    59.166.0.5|7.84|  0.0| null|null|\n",
      "|  175.45.176.3|4.54| 22.4| -1.6|0.29|\n",
      "+--------------+----+-----+-----+----+\n",
      "\n",
      "Variable  srcip  total Information Value =>  1.89\n",
      "+---------+-----+-----+-----+----+\n",
      "|state_bin| NO_%|YES_%|  WoE|  IV|\n",
      "+---------+-----+-----+-----+----+\n",
      "|      CON|22.24| 0.17| 4.89|1.08|\n",
      "|      FIN|58.17|64.45| -0.1|0.01|\n",
      "|      INT| 19.2|33.59|-0.56|0.08|\n",
      "|    other| 0.39| 1.79|-1.51|0.02|\n",
      "+---------+-----+-----+-----+----+\n",
      "\n",
      "Variable  state  total Information Value =>  1.1900000000000002\n",
      "+-------------------+-----+-----+----+----+\n",
      "|is_sm_ips_ports_bin| NO_%|YES_%| WoE|  IV|\n",
      "+-------------------+-----+-----+----+----+\n",
      "|                  1| 0.17|  0.0|null|null|\n",
      "|                  0|99.83|100.0| 0.0| 0.0|\n",
      "+-------------------+-----+-----+----+----+\n",
      "\n",
      "Variable  is_sm_ips_ports  total Information Value =>  0.0\n",
      "+---------+-----+-----+-----+----+\n",
      "|proto_bin| NO_%|YES_%|  WoE|  IV|\n",
      "+---------+-----+-----+-----+----+\n",
      "|      udp|39.09|26.48| 0.39|0.05|\n",
      "|      tcp|58.82|64.46|-0.09|0.01|\n",
      "|    other| 2.09| 9.06|-1.46| 0.1|\n",
      "+---------+-----+-----+-----+----+\n",
      "\n",
      "Variable  proto  total Information Value =>  0.16000000000000003\n",
      "+----------------+-----+-----+-----+----+\n",
      "|is_ftp_login_bin| NO_%|YES_%|  WoE|  IV|\n",
      "+----------------+-----+-----+-----+----+\n",
      "|             0.0|42.31|  0.0| null|null|\n",
      "|             2.0|  0.0| 0.02|-3.01| 0.0|\n",
      "|             4.0| 0.01|  0.0| null|null|\n",
      "|             1.0| 1.72| 0.66| 0.95|0.01|\n",
      "|         missing|55.97|99.32|-0.57|0.25|\n",
      "+----------------+-----+-----+-----+----+\n",
      "\n",
      "Variable  is_ftp_login  total Information Value =>  0.26\n",
      "+-----------+-----+-----+-----+----+\n",
      "|service_bin| NO_%|YES_%|  WoE|  IV|\n",
      "+-----------+-----+-----+-----+----+\n",
      "|        dns|30.99| 1.89|  2.8|0.81|\n",
      "|        ftp| 1.93| 2.91|-0.41| 0.0|\n",
      "|       smtp| 3.24|  0.0| null|null|\n",
      "|        ssh| 1.87|  0.0| null|null|\n",
      "|        ssl| 0.01|  0.0| null|null|\n",
      "|       snmp|  0.0|  0.0| null|null|\n",
      "|       dhcp| 0.01|  0.0| null|null|\n",
      "|     radius|  0.0|  0.0| null|null|\n",
      "|          -|48.75|90.49|-0.62|0.26|\n",
      "|       pop3| 0.06|  0.0| null|null|\n",
      "|        irc|  0.0|  0.0| null|null|\n",
      "|       http| 8.15| 4.71| 0.55|0.02|\n",
      "|   ftp-data| 4.99|  0.0| null|null|\n",
      "+-----------+-----+-----+-----+----+\n",
      "\n",
      "Variable  service  total Information Value =>  1.09\n",
      "+--------------+-----+-----+-----+----+\n",
      "|ct_ftp_cmd_bin| NO_%|YES_%|  WoE|  IV|\n",
      "+--------------+-----+-----+-----+----+\n",
      "|             8|  0.0|  0.0| null|null|\n",
      "|             4| 0.04|  0.0| null|null|\n",
      "|             5| 0.01|  0.0| null|null|\n",
      "|              |55.97|99.32|-0.57|0.25|\n",
      "|             6| 0.01|  0.0| null|null|\n",
      "|             1| 1.58| 0.66| 0.87|0.01|\n",
      "|             0|42.31|  0.0| null|null|\n",
      "|             2| 0.05| 0.02| 0.87| 0.0|\n",
      "|             3| 0.03|  0.0| null|null|\n",
      "+--------------+-----+-----+-----+----+\n",
      "\n",
      "Variable  ct_ftp_cmd  total Information Value =>  0.26"
     ]
    }
   ],
   "source": [
    "\n",
    "def woe_cat(main_df, list_of_cat=list, var_list=list, iv_list=list):\n",
    "    main_df=main_df.select(*['PK_column', 'target'], *list_of_cat).fillna('missing')\n",
    "    n=int(main_df.groupBy('target').count().collect()[1][1])\n",
    "    y=int(main_df.groupBy('target').count().collect()[0][1])\n",
    "    for predictor in list_of_cat:\n",
    "        predictor_bin=predictor+'_bin'\n",
    "        df=main_df.crosstab(predictor,'target')\n",
    "        df = df.withColumn(\"YES_%\",(F.col(\"YES\")/y))\n",
    "        df = df.withColumn(\"NO_%\",(F.col(\"NO\")/n))\n",
    "        df = df.withColumn(\"WoE\", F.log(F.col(\"NO_%\")/F.col(\"YES_%\")))\n",
    "        df = df.withColumn(\"IV\", F.log(F.col(\"NO_%\") / F.col(\"YES_%\")) * (F.col(\"NO_%\") - F.col(\"YES_%\")))\n",
    "        df = df.withColumnRenamed(df.columns[0],predictor_bin)\n",
    "        df=df.withColumn(\"WoE\",  F.round(df[\"WoE\"], 2)).withColumn(\"IV\",  F.round(df[\"IV\"], 2))\n",
    "        df=df.withColumn(\"NO_%\",  F.round(df[\"NO_%\"]*100, 2)).withColumn(\"YES_%\",  F.round(df[\"YES_%\"]*100, 2))\n",
    "        df=df.select(predictor_bin, 'NO_%', 'YES_%', 'WoE', 'IV')\n",
    "        df.show()\n",
    "        iv_sum = df.groupBy().sum().select(\"sum(IV)\").collect()[0][0]\n",
    "        print('Variable ', predictor, ' total Information Value => ', iv_sum)\n",
    "        var_list.append(predictor)\n",
    "        iv_list.append(iv_sum)\n",
    "    return var_list, iv_list\n",
    "variable_list_cat=[]\n",
    "total_iv_list_cat=[]\n",
    "var_list, iv_list=woe_cat(df_nulls, list(set(categorical)-{'rowId'}), var_list=variable_list_cat, iv_list=total_iv_list_cat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns to drop IV < 0.1 ['is_sm_ips_ports']\n",
      "Top 10 columns ['ct_state_ttl' 'dstip' 'srcip' 'state' 'service' 'dsport' 'is_ftp_login'\n",
      " 'ct_ftp_cmd' 'proto' 'sport']"
     ]
    }
   ],
   "source": [
    "top_10_categorical=iv_check(var_list, iv_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df=df.drop(*['ct_dst_sport_ltm', 'dwin', 'res_bdy_len', 'stcpb', 'swin', 'trans_depth', 'is_sm_ips_ports'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoding of categorical variable... dstip\n",
      "encoding of categorical variable... sport\n",
      "encoding of categorical variable... dsport\n",
      "encoding of categorical variable... ct_state_ttl\n",
      "encoding of categorical variable... srcip\n",
      "encoding of categorical variable... state\n",
      "encoding of categorical variable... is_ftp_login\n",
      "encoding of categorical variable... proto\n",
      "encoding of categorical variable... service\n",
      "encoding of categorical variable... ct_ftp_cmd\n",
      "Number of rows = 2540047 and columns = 128"
     ]
    }
   ],
   "source": [
    "#\n",
    "def encoding_only(df, enc, categorical):\n",
    "    for predictor in categorical:\n",
    "        print('encoding of categorical variable...', predictor)\n",
    "        df_pivot = df.select('rowId', predictor).groupBy('rowId').pivot(predictor).count()\n",
    "        col_names = list(set(df_pivot.columns) - {'rowId'})\n",
    "        for c_name in col_names:\n",
    "            df_pivot = df_pivot.withColumnRenamed(c_name, predictor + '_' + c_name)\n",
    "        df_pivot = df_pivot.fillna(0)\n",
    "        enc = df_pivot.join(enc, df_pivot.rowId == enc.rowId, 'left').drop(enc.rowId)\n",
    "    return enc\n",
    "\n",
    "categorical = [field for (field, dataType) in df.dtypes if dataType == 'string']\n",
    "s = StructType([StructField(\"rowId\", StringType(), True)])\n",
    "enc = spark.createDataFrame([], s)\n",
    "enc_categorical=encoding_only(df, enc, set(categorical)-{'rowId'})\n",
    "\n",
    "#\n",
    "df=df.drop(*list(set(categorical)-{'rowId'}))\n",
    "df=df.join(enc_categorical, df.rowId == enc_categorical.rowId, 'inner').drop(enc_categorical.rowId)\n",
    "print(\"Number of rows = {} and columns = {}\".format(df.count(), len(df.columns)))\n",
    "\n",
    "#\n",
    "for name in df.columns:\n",
    "      df = df.withColumnRenamed(name, name.replace('.', '_'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#\n",
    "def vectorA(df, num_cols):\n",
    "    assembler = VectorAssembler(inputCols=sorted(num_cols), outputCol='features')\n",
    "    df = assembler.transform(df)\n",
    "    return df\n",
    "def scaling(df):\n",
    "    scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\", withStd=True, withMean=True)\n",
    "    scalerModel = scaler.fit(df)\n",
    "    scaledDF = scalerModel.transform(df)\n",
    "    return scaledDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#\n",
    "vector_cols=list(set(df.columns)-{'target', 'rowId', 'target1', 'target2', 'target3'})\n",
    "df_v=vectorA(df, vector_cols)\n",
    "scaledDF=scaling(df_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlated pair =>  ct_srv_dst  and  Dintpkt\n",
      "correlated pair =>  dstip_149_171_126_0  and  srcip_59_166_0_5\n",
      "correlated pair =>  dmeansz  and  service_-\n",
      "correlated pair =>  state_INT  and  srcip_59_166_0_0\n",
      "correlated pair =>  srcip_59_166_0_2  and  srcip_59_166_0_0\n",
      "correlated pair =>  srcip_149_171_126_18  and  dtcpb\n",
      "correlated pair =>  sport_0  and  dtcpb\n",
      "correlated pair =>  state_FIN  and  dtcpb\n",
      "correlated pair =>  dsport_21  and  dtcpb\n",
      "correlated pair =>  smeansz  and  dmeansz\n",
      "correlated pair =>  service_ftp-data  and  srcip_59_166_0_5\n",
      "correlated pair =>  srcip_175_45_176_1  and  srcip_59_166_0_5\n",
      "correlated pair =>  srcip_other  and  dstip_149_171_126_18\n",
      "correlated pair =>  synack  and  dstip_149_171_126_8\n",
      "correlated pair =>  ct_src_dport_ltm  and  dmeansz\n",
      "correlated pair =>  service_smtp  and  dstip_149_171_126_18\n",
      "correlated pair =>  Sintpkt  and  srcip_149_171_126_10\n",
      "correlated pair =>  dstip_149_171_126_3  and  ct_src_dport_ltm\n",
      "correlated pair =>  service_ssh  and  srcip_59_166_0_7\n",
      "correlated pair =>  ct_state_ttl_3  and  srcip_59_166_0_0\n",
      "correlated pair =>  dstip_149_171_126_7  and  dstip_149_171_126_8\n",
      "correlated pair =>  ct_srv_src  and  srcip_59_166_0_0\n",
      "correlated pair =>  dstip_149_171_126_6  and  state_other\n",
      "correlated pair =>  sport_other  and  srcip_other\n",
      "correlated pair =>  state_CON  and  srcip_other\n",
      "correlated pair =>  sttl  and  dstip_149_171_126_0\n",
      "correlated pair =>  service_dns  and  ct_src_dport_ltm\n",
      "correlated pair =>  is_ftp_login_4_0  and  dmeansz\n",
      "correlated pair =>  service_dhcp  and  dstip_149_171_126_8\n",
      "correlated pair =>  srcip_175_45_176_3  and  Djit\n",
      "correlated pair =>  dsport_53  and  ct_ftp_cmd_ \n",
      "correlated pair =>  ct_state_ttl_6  and  dstip_149_171_126_15\n",
      "correlated pair =>  ct_ftp_cmd_2  and  dstip_149_171_126_0\n",
      "correlated pair =>  ct_flw_http_mthd  and  ct_ftp_cmd_ \n",
      "correlated pair =>  dsport_143  and  state_other\n",
      "correlated pair =>  service_ssl  and  dtcpb\n",
      "correlated pair =>  sbytes  and  dmeansz\n",
      "correlated pair =>  is_ftp_login_0_0  and  service_-\n",
      "correlated pair =>  service_irc  and  service_snmp\n",
      "correlated pair =>  dbytes  and  dstip_other\n",
      "correlated pair =>  dstip_175_45_176_3  and  is_ftp_login_2_0\n",
      "correlated pair =>  dstip_149_171_126_17  and  is_ftp_login_2_0\n",
      "correlated pair =>  dstip_149_171_126_10  and  srcip_149_171_126_10\n",
      "correlated pair =>  srcip_59_166_0_4  and  srcip_149_171_126_10\n",
      "correlated pair =>  ct_ftp_cmd_8  and  sport_other\n",
      "correlated pair =>  service_pop3  and  srcip_other\n",
      "correlated pair =>  dstip_149_171_126_1  and  service_-\n",
      "correlated pair =>  dstip_149_171_126_14  and  dur\n",
      "correlated pair =>  dsport_111  and  dmeansz\n",
      "correlated pair =>  ct_src_ ltm  and  srcip_59_166_0_7\n",
      "correlated pair =>  dstip_175_45_176_0  and  srcip_59_166_0_7\n",
      "51"
     ]
    }
   ],
   "source": [
    "result = Correlation.corr(scaledDF, 'scaledFeatures', method='pearson')\n",
    "result = result.collect()[0][\"pearson({})\".format('scaledFeatures')].values\n",
    "corr_pd_df=pd.DataFrame(result.reshape(-1, len(vector_cols)),\n",
    "columns=vector_cols, index=vector_cols)\n",
    "correlated_features = set()\n",
    "for i in range(len(corr_pd_df.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(corr_pd_df.iloc[i, j]) > 0.5 and corr_pd_df.columns[i] not in correlated_features:\n",
    "            correlated_features.add(corr_pd_df.columns[i])\n",
    "            print(\"correlated pair => \", corr_pd_df.columns[i], ' and ', corr_pd_df.index[j])\n",
    "print(len(correlated_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the function to calculate PCA with known k\n",
    "def pca(df, features, k):\n",
    "    pca = PCA(k=k, inputCol=features, outputCol=\"pcaFeatures\")\n",
    "    model = pca.fit(df)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the function to find best k \n",
    "def pca_k(df, features=\"features\"):\n",
    "    for k in range (50, 130, 2):\n",
    "        model=pca(df, features, k)\n",
    "        if sum(list(model.explainedVariance)) >= 0.95: \n",
    "            print(k) \n",
    "            break\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n",
      "[0.13401840939250606,0.0476674091486717,0.04434563372952574,0.03521484881358813,0.031055141809113857,0.02956061878661711,0.027837626542030782,0.02489161470123653,0.023277946764674425,0.022113424231441994,0.016973849673313134,0.01600351185556135,0.014745767147059836,0.013993543108932043,0.013697614222293212,0.013297982762827003,0.011888382818516221,0.011606460751716794,0.011279224534084932,0.010778533838407931,0.010686283164410363,0.010043937308605071,0.009503888878700576,0.009024509545724672,0.008803863477505357,0.008620174295089123,0.008392567991203184,0.008309549661629934,0.008305101627248698,0.008302685151070638,0.008297680050625065,0.008289722355920338,0.008286826986571147,0.008281915684474365,0.008276372401179809,0.008271429230509003,0.008262968806936225,0.008260056837375353,0.008253837074072469,0.008251777506601287,0.008242560007890271,0.008237869959577643,0.008228091267015809,0.008225182111560241,0.008217336480679436,0.007954657095020837,0.007868541062487862,0.007816334989080092,0.007793653160772812,0.007665263442272197,0.007656534613949186,0.007639390370990176,0.007636264977789944,0.007634392772415114,0.007631701127546715,0.00763055614567784,0.007629324235651074,0.007620808562260683,0.007616543749856094,0.0075356585917044465,0.007471105517751742,0.0073645320110454,0.007225832477574271,0.006543070503964047,0.006357894758572355,0.006241452928063978,0.005775726107309746,0.005554901172567057,0.005371444814090758,0.004587248436504172,0.004454218951365671,0.0042473226685996405]"
     ]
    }
   ],
   "source": [
    "m = pca_k(scaledDF, features='scaledFeatures')\n",
    "df_pca = m.transform(scaledDF)\n",
    "print(m.explainedVariance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12402900234057278,0.04821415446759538,0.04156625460131342,0.03506381496206099,0.03246178537025871,0.02985057714863424,0.0269544552206585,0.0250339161562357,0.023171296529383163,0.0219265378305739,0.016961468348385276,0.01594321383326257,0.014830460489077463,0.014425101981016862,0.014324242303574791,0.013187478219048622,0.01245844876685683,0.012093782511061373,0.011765999374369037,0.011391050531808769,0.010639801672139786,0.010018734336994949,0.00947955955795116,0.009367050754522474,0.00914536118341031,0.008897483523359768,0.008849798139620517,0.008845437895517332,0.008841607283304425,0.008837440994613819,0.008828817908153526,0.008825595540267992,0.008820673068458256,0.008814780035488088,0.008809914292757065,0.008800381837114384,0.008797251617101983,0.008790670017196026,0.008788274164148773,0.008778448222682164,0.00877314255621359,0.008762638744519992,0.0087602050481973,0.008751796227951136,0.008434108634929669,0.008366555922543772,0.008323543513731674,0.00829149549166395,0.008163013108816208,0.008150999936425969,0.008135112026464952,0.0081309197463898,0.008129486262252602,0.008127977855094766,0.00812685489691916,0.00812543830210124,0.008111892150113547,0.00810512506970152,0.00802416617944121,0.007865111595555798,0.007790570779027244,0.00725675850758326,0.006908979753236797,0.006712044114314902,0.006521481685740835,0.006144724445099903,0.005800841706847217,0.0057195202740067995,0.004885454248563514,0.00472856379903997,0.004456529161646167,0.004029432234918965]"
     ]
    }
   ],
   "source": [
    "#\n",
    "m = pca(scaledDF, \"scaledFeatures\", 72)\n",
    "df_pca = m.transform(scaledDF)\n",
    "print(m.explainedVariance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#\n",
    "df_final=df_pca\n",
    "df_final=df_final.randomSplit([0.8,0.2],24)\n",
    "train=df_final[0]\n",
    "test=df_final[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def area_under(result, labelCol=\"target\" ):\n",
    "    evaluator=BinaryClassificationEvaluator(rawPredictionCol= \"probability\",labelCol=labelCol)\n",
    "    print(\"The area under ROC curve = {}\".format(round(evaluator.evaluate(result), 5)))\n",
    "    evaluator=BinaryClassificationEvaluator(rawPredictionCol= \"probability\",labelCol=labelCol, metricName=\"areaUnderPR\")\n",
    "    print(\"The area under Precision-Recall curve = {}\".format(round(evaluator.evaluate(result), 5)))\n",
    "def conf_matrix(result, target):\n",
    "    tp=result[(result[target]==1)&(result.prediction==1)].shape()[0]\n",
    "    fn=result[(result[target]==1)&(result.prediction==0)].shape()[0]\n",
    "    fp=result[(result[target]==0)&(result.prediction==1)].shape()[0]\n",
    "    tn=result[(result[target]==0)&(result.prediction==0)].shape()[0]\n",
    "    print(\"TP = \", tp)\n",
    "    print(\"FN = \",fn)\n",
    "    print(\"FP = \", fp)\n",
    "    print(\"TN = \", tn)\n",
    "    if ((tp+fn)>0)&((tp+fp)>0):\n",
    "        print('recall = ', round(tp/(tp+fn), 5) )\n",
    "        print('precision = ', round(tp/(tp+fp), 5))\n",
    "    else: print('recall and precision is 0')\n",
    "    print('accuracy =', round((tp+tn)/(tp+tn+fn+fp),5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under Precision-Recall curve = 0.59"
     ]
    }
   ],
   "source": [
    "evaluator=BinaryClassificationEvaluator(rawPredictionCol= \"probability\",labelCol=\"target3\", metricName=\"areaUnderPR\")\n",
    "RandomForest= RandomForestClassifier(featuresCol='pcaFeatures', labelCol=\"target3\" )\n",
    "\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(RandomForest.maxDepth, [2, 5, 10, 15, 20])\n",
    "             .addGrid(RandomForest.minInfoGain, [0.0, 0.03, 0.1])\n",
    "             .addGrid(RandomForest.numTrees, [5, 20, 50, 100, 128])\n",
    "             .addGrid(RandomForest.impurity, ['entropy', 'gini'])\n",
    "             .build())\n",
    "\n",
    "cv = CrossValidator(estimator = RandomForest,\n",
    "                      estimatorParamMaps = paramGrid,\n",
    "                      evaluator = evaluator,\n",
    "                      numFolds = 5)\n",
    "\n",
    "cvModel = cv.fit(train)\n",
    "result=cvModel.transform(test)\n",
    "print(\"The area under Precision-Recall for test set after CV  is {}\".format(evaluator.evaluate(result)))\n",
    "\n",
    "RandomForest= RandomForestClassifier(featuresCol='pcaFeatures', labelCol=\"target3\", numTrees = 128, maxDepth=15 )\n",
    "RF_model=RandomForest.fit(train)\n",
    "result=RF_model.transform(test)\n",
    "evaluator=BinaryClassificationEvaluator(rawPredictionCol= \"probability\",labelCol=\"target3\", metricName=\"areaUnderPR\")\n",
    "print(\"The area under Precision-Recall curve = {}\".format(round(evaluator.evaluate(result), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Param(parent='RandomForestClassifier_40ce83b394027d5bf0ee', name='cacheNodeIds', doc='If false, the algorithm will pass trees to executors to match instances with nodes. If true, the algorithm will cache node IDs for each instance. Caching can speed up training of deeper trees.'): False, Param(parent='RandomForestClassifier_40ce83b394027d5bf0ee', name='checkpointInterval', doc='set checkpoint interval (>= 1) or disable checkpoint (-1). E.g. 10 means that the cache will get checkpointed every 10 iterations. Note: this setting will be ignored if the checkpoint directory is not set in the SparkContext'): 10, Param(parent='RandomForestClassifier_40ce83b394027d5bf0ee', name='featureSubsetStrategy', doc='The number of features to consider for splits at each tree node. Supported options: auto, all, onethird, sqrt, log2, (0.0-1.0], [1-n].'): 'auto', Param(parent='RandomForestClassifier_40ce83b394027d5bf0ee', name='featuresCol', doc='features column name'): 'pcaFeatures', Param(parent='RandomForestClassifier_40ce83b394027d5bf0ee', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini', Param(parent='RandomForestClassifier_40ce83b394027d5bf0ee', name='labelCol', doc='label column name'): 'target3', Param(parent='RandomForestClassifier_40ce83b394027d5bf0ee', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 32, Param(parent='RandomForestClassifier_40ce83b394027d5bf0ee', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 15, Param(parent='RandomForestClassifier_40ce83b394027d5bf0ee', name='maxMemoryInMB', doc='Maximum memory in MB allocated to histogram aggregation.'): 256, Param(parent='RandomForestClassifier_40ce83b394027d5bf0ee', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.0, Param(parent='RandomForestClassifier_40ce83b394027d5bf0ee', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split.  If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent='RandomForestClassifier_40ce83b394027d5bf0ee', name='numTrees', doc='Number of trees to train (>= 1)'): 128, Param(parent='RandomForestClassifier_40ce83b394027d5bf0ee', name='predictionCol', doc='prediction column name'): 'prediction', Param(parent='RandomForestClassifier_40ce83b394027d5bf0ee', name='probabilityCol', doc='Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities'): 'probability', Param(parent='RandomForestClassifier_40ce83b394027d5bf0ee', name='rawPredictionCol', doc='raw prediction (a.k.a. confidence) column name'): 'rawPrediction', Param(parent='RandomForestClassifier_40ce83b394027d5bf0ee', name='seed', doc='random seed'): -5387697053847413545, Param(parent='RandomForestClassifier_40ce83b394027d5bf0ee', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0}"
     ]
    }
   ],
   "source": [
    "bestModel = cvModel.bestModel\n",
    "bestModel.extractParamMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under ROC curve = 0.99968\n",
      "The area under Precision-Recall curve = 0.99781\n",
      "TP =  62184\n",
      "FN =  2113\n",
      "FP =  1612\n",
      "TN =  442139\n",
      "recall =  0.96714\n",
      "precision =  0.97473\n",
      "accuracy = 0.99267"
     ]
    }
   ],
   "source": [
    "RandomForest= RandomForestClassifier(featuresCol='pcaFeatures', labelCol=\"target\", numTrees = 128, maxDepth=15 )\n",
    "RF_model=RandomForest.fit(train)\n",
    "result=RF_model.transform(test)\n",
    "area_under(result, labelCol=\"target\" )\n",
    "conf_matrix(result, \"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under ROC curve = 0.9997\n",
      "The area under Precision-Recall curve = 0.99739\n",
      "TP =  42044\n",
      "FN =  1059\n",
      "FP =  39\n",
      "TN =  464906\n",
      "recall =  0.97543\n",
      "precision =  0.99907\n",
      "accuracy = 0.99784"
     ]
    }
   ],
   "source": [
    "RandomForest= RandomForestClassifier(featuresCol='pcaFeatures', labelCol=\"target1\", numTrees = 128, maxDepth=15 )\n",
    "RF_model=RandomForest.fit(train)\n",
    "result=RF_model.transform(test)\n",
    "area_under(result, labelCol=\"target1\" )\n",
    "conf_matrix(result, \"target1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under ROC curve = 0.99517\n",
      "The area under Precision-Recall curve = 0.77001\n",
      "TP =  5047\n",
      "FN =  3848\n",
      "FP =  2006\n",
      "TN =  497147\n",
      "recall =  0.5674\n",
      "precision =  0.71558\n",
      "accuracy = 0.98848"
     ]
    }
   ],
   "source": [
    "RandomForest= RandomForestClassifier(featuresCol='pcaFeatures', labelCol=\"target2\", numTrees = 128, maxDepth=15 )\n",
    "RF_model=RandomForest.fit(train)\n",
    "result=RF_model.transform(test)\n",
    "area_under(result, labelCol=\"target2\" )\n",
    "conf_matrix(result, \"target2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under ROC curve = 0.99472\n",
      "The area under Precision-Recall curve = 0.58478\n",
      "TP =  1048\n",
      "FN =  2785\n",
      "FP =  501\n",
      "TN =  503756\n",
      "recall =  0.27342\n",
      "precision =  0.67657\n",
      "accuracy = 0.99353"
     ]
    }
   ],
   "source": [
    "RandomForest= RandomForestClassifier(featuresCol='pcaFeatures', labelCol=\"target3\", numTrees = 128, maxDepth=15 )\n",
    "RF_model=RandomForest.fit(train)\n",
    "result=RF_model.transform(test)\n",
    "area_under(result, labelCol=\"target3\" )\n",
    "conf_matrix(result, \"target3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBT Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.ml.classification import  GBTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluator=BinaryClassificationEvaluator(rawPredictionCol= \"probability\",labelCol=\"target3\", metricName=\"areaUnderPR\")\n",
    "GBT= GBTClassifier(featuresCol='pcaFeatures', labelCol=\"target3\")\n",
    "\n",
    "# Create ParamGrid for Cross Validation\n",
    "paramGrid = (ParamGridBuilder().addGrid(GBT.maxDepth, [5, 10, 15, 20]).build())\n",
    "# Cross validate\n",
    "cv = CrossValidator(estimator = GBT,estimatorParamMaps = paramGrid,evaluator = evaluator, numFolds = 5)\n",
    "# Fit the training set and transform the testing set\n",
    "cvModel = cv.fit(train)\n",
    "result=cvModel.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"cacheNodeIds: If false, the algorithm will pass trees to executors to match instances with nodes. If true, the algorithm will cache node IDs for each instance. Caching can speed up training of deeper trees. (default: False)\\ncheckpointInterval: set checkpoint interval (>= 1) or disable checkpoint (-1). E.g. 10 means that the cache will get checkpointed every 10 iterations. Note: this setting will be ignored if the checkpoint directory is not set in the SparkContext (default: 10)\\nfeatureSubsetStrategy: The number of features to consider for splits at each tree node. Supported options: auto, all, onethird, sqrt, log2, (0.0-1.0], [1-n]. (undefined)\\nfeaturesCol: features column name (default: features, current: pcaFeatures)\\nimpurity: Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini (undefined)\\nlabelCol: label column name (default: label, current: target3)\\nlossType: Loss function which GBT tries to minimize (case-insensitive). Supported options: logistic (default: logistic)\\nmaxBins: Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature. (default: 32)\\nmaxDepth: Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. (default: 5, current: 15)\\nmaxIter: maximum number of iterations (>= 0) (default: 20)\\nmaxMemoryInMB: Maximum memory in MB allocated to histogram aggregation. (default: 256)\\nminInfoGain: Minimum information gain for a split to be considered at a tree node. (default: 0.0)\\nminInstancesPerNode: Minimum number of instances each child must have after split.  If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1. (default: 1)\\npredictionCol: prediction column name (default: prediction)\\nprobabilityCol: Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities (undefined)\\nrawPredictionCol: raw prediction (a.k.a. confidence) column name (undefined)\\nseed: random seed (default: 3504127614838123891)\\nstepSize: Step size (a.k.a. learning rate) in interval (0, 1] for shrinking the contribution of each estimator. (default: 0.1)\\nsubsamplingRate: Fraction of the training data used for learning each decision tree, in range (0, 1]. (default: 1.0)\\nthresholds: Thresholds in multi-class classification to adjust the probability of predicting each class. Array must have length equal to the number of classes, with values > 0 excepting that at most one value may be 0. The class with largest value p/t is predicted, where p is the original probability of that class and t is the class's threshold (undefined)\""
     ]
    }
   ],
   "source": [
    "#list of best model parameters\n",
    "bestModelGBT = cvModel.bestModel\n",
    "bestModelGBT.explainParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under ROC curve = 0.99986\n",
      "The area under Precision-Recall curve = 0.99901\n",
      "TP =  63188\n",
      "FN =  1066\n",
      "FP =  684\n",
      "TN =  443152\n",
      "recall =  0.98341\n",
      "precision =  0.98929\n",
      "accuracy = 0.99656"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import  GBTClassifier\n",
    "GBT= GBTClassifier(featuresCol='pcaFeatures', labelCol=\"target\", maxDepth=15 )\n",
    "GBT_model=GBT.fit(train)\n",
    "result=GBT_model.transform(test)\n",
    "area_under(result, labelCol=\"target\" )\n",
    "conf_matrix(result, \"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under ROC curve = 0.99986\n",
      "The area under Precision-Recall curve = 0.99871\n",
      "TP =  42648\n",
      "FN =  579\n",
      "FP =  55\n",
      "TN =  464808\n",
      "recall =  0.98661\n",
      "precision =  0.99871\n",
      "accuracy = 0.99875"
     ]
    }
   ],
   "source": [
    "GBT= GBTClassifier(featuresCol='pcaFeatures', labelCol=\"target1\", maxDepth=15)\n",
    "GBT_model=GBT.fit(train)\n",
    "result=GBT_model.transform(test)\n",
    "area_under(result, labelCol=\"target1\" )\n",
    "conf_matrix(result, \"target1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under ROC curve = 0.99279\n",
      "The area under Precision-Recall curve = 0.75387\n",
      "TP =  5024\n",
      "FN =  3802\n",
      "FP =  2053\n",
      "TN =  497211\n",
      "recall =  0.56923\n",
      "precision =  0.70991\n",
      "accuracy = 0.98848"
     ]
    }
   ],
   "source": [
    "GBT= GBTClassifier(featuresCol='pcaFeatures', labelCol=\"target2\", maxDepth=15)\n",
    "GBT_model=GBT.fit(train)\n",
    "result=GBT_model.transform(test)\n",
    "area_under(result, labelCol=\"target2\" )\n",
    "conf_matrix(result, \"target2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under ROC curve = 0.9211\n",
      "The area under Precision-Recall curve = 0.08168\n",
      "TP =  135\n",
      "FN =  3714\n",
      "FP =  6935\n",
      "TN =  497306\n",
      "recall =  0.03507\n",
      "precision =  0.01909\n",
      "accuracy = 0.97904"
     ]
    }
   ],
   "source": [
    "GBT= GBTClassifier(featuresCol='pcaFeatures', labelCol=\"target2\", maxDepth=15)\n",
    "GBT_model=GBT.fit(train)\n",
    "result=GBT_model.transform(test)\n",
    "area_under(result, labelCol=\"target3\" )\n",
    "conf_matrix(result, \"target3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under ROC curve = 0.99924\n",
      "The area under Precision-Recall curve = 0.99458\n",
      "TP =  61968\n",
      "FN =  2286\n",
      "FP =  3701\n",
      "TN =  440135\n",
      "recall =  0.96442\n",
      "precision =  0.94364\n",
      "accuracy = 0.98822"
     ]
    }
   ],
   "source": [
    "LR= LogisticRegression(featuresCol='pcaFeatures', labelCol=\"target\")\n",
    "LR_model=LR.fit(train)\n",
    "result=LR_model.transform(test)\n",
    "area_under(result, labelCol=\"target\" )\n",
    "conf_matrix(result, \"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under ROC curve = 0.99931\n",
      "The area under Precision-Recall curve = 0.99577\n",
      "TP =  42141\n",
      "FN =  1094\n",
      "FP =  122\n",
      "TN =  464733\n",
      "recall =  0.9747\n",
      "precision =  0.99711\n",
      "accuracy = 0.99761"
     ]
    }
   ],
   "source": [
    "LR= LogisticRegression(featuresCol='pcaFeatures', labelCol=\"target1\")\n",
    "LR_model=LR.fit(train)\n",
    "result=LR_model.transform(test)\n",
    "area_under(result, labelCol=\"target1\" )\n",
    "conf_matrix(result, \"target1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under ROC curve = 0.99178\n",
      "The area under Precision-Recall curve = 0.65982\n",
      "TP =  4286\n",
      "FN =  4536\n",
      "FP =  2080\n",
      "TN =  497188\n",
      "recall =  0.48583\n",
      "precision =  0.67326\n",
      "accuracy = 0.98698"
     ]
    }
   ],
   "source": [
    "LR= LogisticRegression(featuresCol='pcaFeatures', labelCol=\"target2\") \n",
    "LR_model=LR.fit(train)\n",
    "result=LR_model.transform(test)\n",
    "area_under(result, labelCol=\"target2\" )\n",
    "conf_matrix(result, \"target2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under ROC curve = 0.99173\n",
      "The area under Precision-Recall curve = 0.34504\n",
      "TP =  189\n",
      "FN =  3644\n",
      "FP =  327\n",
      "TN =  503930\n",
      "recall =  0.04931\n",
      "precision =  0.36628\n",
      "accuracy = 0.99218"
     ]
    }
   ],
   "source": [
    "LR= LogisticRegression(featuresCol='pcaFeatures', labelCol=\"target3\")\n",
    "LR_model=LR.fit(train)\n",
    "result=LR_model.transform(test)\n",
    "area_under(result, labelCol=\"target3\" )\n",
    "conf_matrix(result, \"target3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.ml.classification import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SVM= LinearSVC(featuresCol='pcaFeatures', labelCol=\"target\")\n",
    "SVM_model=SVM.fit(train)\n",
    "result=SVM_model.transform(test)\n",
    "result=result.withColumn('prediction',F.col('prediction').cast(IntegerType()))\n",
    "#area_under(result, labelCol=\"target\" )\n",
    "#conf_matrix(result, \"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP =  64025\n",
      "FN =  272\n",
      "FP =  5947\n",
      "TN =  437804\n",
      "recall =  0.99577\n",
      "precision =  0.91501\n",
      "accuracy = 0.98776"
     ]
    }
   ],
   "source": [
    "#area_under(result, labelCol=\"target\" )\n",
    "conf_matrix(result, \"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP =  42112\n",
      "FN =  1123\n",
      "FP =  78\n",
      "TN =  464777\n",
      "recall =  0.97403\n",
      "precision =  0.99815\n",
      "accuracy = 0.99764"
     ]
    }
   ],
   "source": [
    "#LinearSVC\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "SVM= LinearSVC(featuresCol='pcaFeatures', labelCol=\"target1\")\n",
    "SVM_model=SVM.fit(train)\n",
    "result=SVM_model.transform(test)\n",
    "result=result.withColumn('prediction',F.col('prediction').cast(IntegerType()))\n",
    "#area_under(result, labelCol=\"target1\" )\n",
    "conf_matrix(result, \"target1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP =  4111\n",
      "FN =  4711\n",
      "FP =  2219\n",
      "TN =  497049\n",
      "recall =  0.46599\n",
      "precision =  0.64945\n",
      "accuracy = 0.98636"
     ]
    }
   ],
   "source": [
    "#LinearSVC\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "SVM= LinearSVC(featuresCol='pcaFeatures', labelCol=\"target2\")\n",
    "SVM_model=SVM.fit(train)\n",
    "result=SVM_model.transform(test)\n",
    "result=result.withColumn('prediction',F.col('prediction').cast(IntegerType()))\n",
    "#area_under(result, labelCol=\"target2\" )\n",
    "conf_matrix(result, \"target2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP =  0\n",
      "FN =  3833\n",
      "FP =  1\n",
      "TN =  504256\n",
      "recall =  0.0\n",
      "precision =  0.0\n",
      "accuracy = 0.99245"
     ]
    }
   ],
   "source": [
    "LinearSVC\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "SVM= LinearSVC(featuresCol='pcaFeatures', labelCol=\"target3\")\n",
    "SVM_model=SVM.fit(train)\n",
    "result=SVM_model.transform(test)\n",
    "result=result.withColumn('prediction',F.col('prediction').cast(IntegerType()))\n",
    "#area_under(result, labelCol=\"target3\" )\n",
    "conf_matrix(result, \"target3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|prediction| count|\n",
      "+----------+------+\n",
      "|         1| 69972|\n",
      "|         0|438076|\n",
      "+----------+------+"
     ]
    }
   ],
   "source": [
    "result.groupBy('prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result=result.withColumn('prediction',F.col('prediction').cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bisecting K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.ml.clustering import BisectingKMeans\n",
    "BM=BisectingKMeans(featuresCol='pcaFeatures', k=2, seed=24)\n",
    "BM_model=BM.fit(df_pca)\n",
    "resultBM=BM_model.transform(df_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Within Set Sum of Squared Errors = 284064978.194632\n",
      "+----------+-------+\n",
      "|prediction|  count|\n",
      "+----------+-------+\n",
      "|         1|1492269|\n",
      "|         0|1047778|\n",
      "+----------+-------+\n",
      "\n",
      "TP =  58190\n",
      "FN =  263093\n",
      "FP =  1434079\n",
      "TN =  784685\n",
      "recall =  0.18112\n",
      "precision =  0.03899\n",
      "accuracy = 0.33183\n",
      "TP =  3118\n",
      "FN =  212363\n",
      "FP =  1489151\n",
      "TN =  835415\n",
      "recall =  0.01447\n",
      "precision =  0.00209\n",
      "accuracy = 0.33012\n",
      "TP =  27443\n",
      "FN =  17082\n",
      "FP =  1464826\n",
      "TN =  1030696\n",
      "recall =  0.61635\n",
      "precision =  0.01839\n",
      "accuracy = 0.41658\n",
      "TP =  12374\n",
      "FN =  6821\n",
      "FP =  1479895\n",
      "TN =  1040957\n",
      "recall =  0.64465\n",
      "precision =  0.00829\n",
      "accuracy = 0.41469"
     ]
    }
   ],
   "source": [
    "# Evaluate clustering.\n",
    "cost = BM_model.computeCost(df_pca)\n",
    "print(\"Within Set Sum of Squared Errors = \" + str(cost))\n",
    "\n",
    "resultBM.groupBy('prediction').count().show()\n",
    "conf_matrix(resultBM, \"target\")\n",
    "conf_matrix(resultBM, \"target1\")\n",
    "conf_matrix(resultBM, \"target2\")\n",
    "conf_matrix(resultBM, \"target3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP =  3454\n",
      "FN =  212027\n",
      "FP =  2057041\n",
      "TN =  267525\n",
      "recall =  0.01603\n",
      "precision =  0.00168\n",
      "accuracy = 0.10668\n",
      "TP =  28367\n",
      "FN =  16158\n",
      "FP =  2032128\n",
      "TN =  463394\n",
      "recall =  0.6371\n",
      "precision =  0.01377\n",
      "accuracy = 0.1936\n",
      "TP =  13651\n",
      "FN =  5544\n",
      "FP =  2046844\n",
      "TN =  474008\n",
      "recall =  0.71117\n",
      "precision =  0.00663\n",
      "accuracy = 0.19199"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "KM=KMeans(featuresCol='pcaFeatures', k=2, seed=24)\n",
    "KM_model=KM.fit(df_pca)\n",
    "resultKM=KM_model.transform(df_pca)\n",
    "conf_matrix(resultKM, \"target1\")\n",
    "conf_matrix(resultKM, \"target2\")\n",
    "conf_matrix(resultKM, \"target3\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
